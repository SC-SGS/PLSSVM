<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>PLSSVM - Parallel Least-Squares Support Vector Machine: Least-Squares Support-Vector Machine</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">PLSSVM - Parallel Least-Squares Support Vector Machine
   &#160;<span id="projectnumber">1.0.1</span>
   </div>
   <div id="projectbrief">A Support Vector Machine implementation using different backends.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Least-Squares Support-Vector Machine </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_README"></a> <a href="https://www.codacy.com/gh/SC-SGS/PLSSVM/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=SC-SGS/PLSSVM&amp;utm_campaign=Badge_Grade"><img src="https://app.codacy.com/project/badge/Grade/e780a63075ce40c29c49d3df4f57c2af" alt="Codacy Badge" class="inline"/></a> &ensp; <a href="https://sc-sgs.github.io/PLSSVM/"><img src="https://github.com/SC-SGS/PLSSVM/actions/workflows/documentation.yml/badge.svg" alt="Generate documentation" style="pointer-events: none;" class="inline"/></a> &ensp; <a href="https://simsgs.informatik.uni-stuttgart.de/jenkins/view/PLSSVM/job/PLSSVM/job/Multibranch-Github/job/main/"><img src="https://simsgs.informatik.uni-stuttgart.de/jenkins/buildStatus/icon?job=PLSSVM%2FMultibranch-Github%2Fmain&amp;subject=Linux+CPU/GPU" alt="Build Status Linux CPU + GPU" class="inline"/></a> &ensp; <a href="https://github.com/SC-SGS/PLSSVM/actions/workflows/msvc_windows.yml"><img src="https://github.com/SC-SGS/PLSSVM/actions/workflows/msvc_windows.yml/badge.svg" alt="Windows CPU" style="pointer-events: none;" class="inline"/></a></p>
<p>Implementation of a parallel <a href="https://en.wikipedia.org/wiki/Least-squares_support-vector_machine">least-squares support-vector machine</a> using multiple different backends. The currently available backends are:</p><ul>
<li><a href="https://www.openmp.org/">OpenMP</a></li>
<li><a href="https://developer.nvidia.com/cuda-zone">CUDA</a></li>
<li><a href="https://www.khronos.org/opencl/">OpenCL</a></li>
<li><a href="https://www.khronos.org/sycl/">SYCL</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md1"></a>
Getting Started</h1>
<h2><a class="anchor" id="autotoc_md2"></a>
Dependencies</h2>
<p>General dependencies:</p><ul>
<li>a C++17 capable compiler (e.g. <a href="https://gcc.gnu.org/"><code>gcc</code></a> or <a href="https://clang.llvm.org/"><code>clang</code></a>)</li>
<li><a href="https://cmake.org/">CMake</a> 3.18 or newer</li>
<li><a href="https://github.com/jarro2783/cxxopts">cxxopts</a>, <a href="https://github.com/fastfloat/fast_float">fast_float</a> and <a href="https://github.com/fmtlib/fmt">{fmt}</a> (all three are automatically build during the CMake configuration if they couldn't be found using the respective <code>find_package</code> call)</li>
<li><a href="https://github.com/google/googletest">GoogleTest</a> if testing is enabled (automatically build during the CMake configuration if <code>find_package(GTest)</code> wasn't successful)</li>
<li><a href="https://www.doxygen.nl/index.html">doxygen</a> if documentation generation is enabled</li>
<li><a href="https://www.openmp.org/">OpenMP</a> 4.0 or newer (optional) to speed-up file parsing</li>
</ul>
<p>Additional dependencies for the OpenMP backend:</p><ul>
<li>compiler with OpenMP support</li>
</ul>
<p>Additional dependencies for the CUDA backend:</p><ul>
<li>CUDA SDK</li>
<li>either NVIDIA <a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html"><code>nvcc</code></a> or <a href="https://llvm.org/docs/CompileCudaWithLLVM.html"><code>clang</code> with CUDA support enabled</a></li>
</ul>
<p>Additional dependencies for the OpenCL backend:</p><ul>
<li>OpenCL runtime and header files</li>
</ul>
<p>Additional dependencies for the SYCL backend:</p><ul>
<li>the code must be compiled with a SYCL capable compiler; currently tested with <a href="https://github.com/intel/llvm">DPC++</a> and <a href="https://github.com/illuhad/hipSYCL">hipSYCL</a></li>
</ul>
<p>Additional dependencies if <code>PLSSVM_ENABLE_TESTING</code> and <code>PLSSVM_GENERATE_TEST_FILE</code> are both set to <code>ON</code>:</p><ul>
<li><a href="https://www.python.org/">Python3</a> with the <a href="https://docs.python.org/3/library/argparse.html"><code>argparse</code></a>, <a href="https://docs.python.org/3/library/timeit.html"><code>timeit</code></a> and <a href="https://scikit-learn.org/stable/"><code>sklearn</code></a> modules</li>
</ul>
<h2><a class="anchor" id="autotoc_md3"></a>
Building</h2>
<p>Building the library can be done using the normal CMake approach:</p>
<div class="fragment"><div class="line">&gt; git clone git@gitlab-sim.informatik.uni-stuttgart.de:vancraar/Bachelor-Code.git SVM</div>
<div class="line">&gt; cd SVM/SVM</div>
<div class="line">&gt; mkdir build &amp;&amp; cd build</div>
<div class="line">&gt; cmake -DPLSSVM_TARGET_PLATFORMS=&quot;...&quot; [optional_options] ..</div>
<div class="line">&gt; cmake --build .</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md4"></a>
Target Platform Selection</h3>
<p>The <b>required</b> CMake option <code>PLSSVM_TARGET_PLATFORMS</code> is used to determine for which targets the backends should be compiled. Valid targets are:</p><ul>
<li><code>cpu</code>: compile for the CPU; <b>no</b> architectural specifications is allowed</li>
<li><code>nvidia</code>: compile for NVIDIA GPUs; <b>at least one</b> architectural specification is necessary, e.g. <code>nvidia:sm_86,sm_70</code></li>
<li><code>amd</code>: compile for AMD GPUs; <b>at least one</b> architectural specification is necessary, e.g. <code>amd:gfx906</code></li>
<li><code>intel</code>: compile for Intel GPUs; <b>no</b> architectural specification is allowed</li>
</ul>
<p>At least one of the above targets must be present.</p>
<p>To retrieve the architectural specification, given an NVIDIA or AMD GPU name, a simple Python3 script <code>utility/gpu_name_to_arch.py</code> is provided (requiring Python3 <a href="https://docs.python.org/3/library/argparse.html"><code>argparse</code></a> as dependency):</p>
<div class="fragment"><div class="line">&gt; python3 utility/gpu_name_to_arch.py --help</div>
<div class="line">usage: gpu_name_to_arch.py [-h] [--name NAME]</div>
<div class="line"> </div>
<div class="line">optional arguments:</div>
<div class="line">  -h, --help   show this help message and exit</div>
<div class="line">  --name NAME  the full name of the GPU (e.g. GeForce RTX 3080)</div>
</div><!-- fragment --><p>Example invocations:</p>
<div class="fragment"><div class="line">&gt; python3 utility_scripts/gpu_name_to_arch.py --name &quot;GeForce RTX 3080&quot;</div>
<div class="line">sm_86</div>
<div class="line">&gt; python3 utility_scripts/gpu_name_to_arch.py --name &quot;Radeon VII&quot;</div>
<div class="line">gfx906</div>
</div><!-- fragment --><p>If no GPU name is provided, the script tries to automatically detect any NVIDIA or AMD GPU (requires the Python3 dependencies <a href="https://pypi.org/project/GPUtil/"><code>GPUtil</code></a> and <a href="https://pypi.org/project/pyamdgpuinfo/"><code>pyamdgpuinfo</code></a>).</p>
<p>If the architectural information for the requested GPU could not be retrieved, one option would be to have a look at:</p><ul>
<li>for NVIDIA GPUs: <a href="https://developer.nvidia.com/cuda-gpus">Your GPU Compute Capability</a></li>
<li>for AMD GPUs: <a href="https://github.com/RadeonOpenCompute/ROCm_Documentation/blob/master/ROCm_Compiler_SDK/ROCm-Native-ISA.rst">ROCm Documentation</a></li>
</ul>
<h3><a class="anchor" id="autotoc_md5"></a>
Optional CMake Options</h3>
<p>The <code>[optional_options]</code> can be one or multiple of:</p>
<ul>
<li><code>PLSSVM_ENABLE_OPENMP_BACKEND=ON|OFF|AUTO</code> (default: <code>AUTO</code>):<ul>
<li><code>ON</code>: check for the OpenMP backend and fail if not available</li>
<li><code>AUTO</code>: check for the OpenMP backend but <b>do not</b> fail if not available</li>
<li><code>OFF</code>: do not check for the OpenMP backend</li>
</ul>
</li>
<li><code>PLSSVM_ENABLE_CUDA_BACKEND=ON|OFF|AUTO</code> (default: <code>AUTO</code>):<ul>
<li><code>ON</code>: check for the CUDA backend and fail if not available</li>
<li><code>AUTO</code>: check for the CUDA backend but <b>do not</b> fail if not available</li>
<li><code>OFF</code>: do not check for the CUDA backend</li>
</ul>
</li>
<li><code>PLSSVM_ENABLE_OPENCL_BACKEND=ON|OFF|AUTO</code> (default: <code>AUTO</code>):<ul>
<li><code>ON</code>: check for the OpenCL backend and fail if not available</li>
<li><code>AUTO</code>: check for the OpenCL backend but <b>do not</b> fail if not available</li>
<li><code>OFF</code>: do not check for the OpenCL backend</li>
</ul>
</li>
<li><code>PLSSVM_ENABLE_SYCL_BACKEND=ON|OFF|AUTO</code> (default: <code>AUTO</code>):<ul>
<li><code>ON</code>: check for the SYCL backend and fail if not available</li>
<li><code>AUTO</code>: check for the SYCL backend but <b>do not</b> fail if not available</li>
<li><code>OFF</code>: do not check for the SYCL backend</li>
</ul>
</li>
</ul>
<p><b>Attention:</b> at least one backend must be enabled and available!</p>
<ul>
<li><code>PLSSVM_ENABLE_ASSERTS=ON|OFF</code> (default: <code>OFF</code>): enables custom assertions regardless whether the <code>DEBUG</code> macro is defined or not</li>
<li><code>PLSSVM_THREAD_BLOCK_SIZE</code> (default: <code>16</code>): set a specific thread block size used in the GPU kernels (for fine-tuning optimizations)</li>
<li><code>PLSSVM_INTERNAL_BLOCK_SIZE</code> (default: <code>6</code>: set a specific internal block size used in the GPU kernels (for fine-tuning optimizations)</li>
<li><code>PLSSVM_EXECUTABLES_USE_SINGLE_PRECISION</code> (default: <code>OFF</code>): enables single precision calculations instead of double precision for the <code>svm-train</code> and <code>svm-predict</code> executables</li>
<li><code>PLSSVM_ENABLE_LTO=ON|OFF</code> (default: <code>ON</code>): enable interprocedural optimization (IPO/LTO) if supported by the compiler</li>
<li><code>PLSSVM_ENABLE_DOCUMENTATION=ON|OFF</code> (default: <code>OFF</code>): enable the <code>doc</code> target using doxygen</li>
<li><code>PLSSVM_ENABLE_TESTING=ON|OFF</code> (default: <code>ON</code>): enable testing using GoogleTest and ctest</li>
<li><code>PLSSVM_GENERATE_TIMING_SCRIPT=ON|OFF</code> (default: <code>OFF</code>): configure a timing script usable for performance measurement</li>
</ul>
<p>If <code>PLSSVM_ENABLE_TESTING</code> is set to <code>ON</code>, the following options can also be set:</p><ul>
<li><code>PLSSVM_GENERATE_TEST_FILE=ON|OFF</code> (default: <code>ON</code>): automatically generate test files<ul>
<li><code>PLSSVM_TEST_FILE_NUM_DATA_POINTS</code> (default: <code>5000</code>): the number of data points in the test file</li>
</ul>
</li>
</ul>
<p>If the SYCL backend is available and DPC++ is used, the option <code>PLSSVM_SYCL_DPCPP_USE_LEVEL_ZERO</code> can be used to select Level-Zero as the DPC++ backend instead of OpenCL. To use DPC++ as compiler simply set the <code>CMAKE_CXX_COMPILER</code> to the respective DPC++ clang path during CMake invocation.</p>
<h2><a class="anchor" id="autotoc_md6"></a>
Running the tests</h2>
<p>To run the tests after building the library (with <code>PLSSVM_ENABLE_TESTING</code> set to <code>ON</code>) use:</p>
<div class="fragment"><div class="line">&gt; ctest</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md7"></a>
Generating test coverage results</h2>
<p>To enable the generation of test coverage reports using <code>locv</code> the library must be compiled using the custom <code>Coverage</code> <code>CMAKE_BUILD_TYPE</code>. Additionally, it's advisable to use smaller test files to shorten the <code>ctest</code> step.</p>
<div class="fragment"><div class="line">&gt; cmake -DCMAKE_BUILD_TYPE=Coverage -DPLSSVM_TARGET_PLATFORMS=&quot;...&quot; \</div>
<div class="line">        -DPLSSVM_TEST_FILE_NUM_DATA_POINTS=100 \</div>
<div class="line">        -DPLSSVM_TEST_FILE_NUM_FEATURES=50 ..</div>
<div class="line">&gt; cmake --build . -- coverage</div>
</div><!-- fragment --><p>The resulting <code>html</code> coverage report is located in the <code>coverage</code> folder in the build directory.</p>
<h2><a class="anchor" id="autotoc_md8"></a>
Creating the documentation</h2>
<p>If doxygen is installed and <code>PLSSVM_ENABLE_DOCUMENTATION</code> is set to <code>ON</code> the documentation can be build using </p><div class="fragment"><div class="line">&gt; make doc</div>
</div><!-- fragment --><p> The documentation of the current state of the main branch can be found <a href="https://sc-sgs.github.io/PLSSVM/">here</a>.</p>
<h1><a class="anchor" id="autotoc_md9"></a>
Installing</h1>
<p>The library supports the <code>install</code> target:</p>
<div class="fragment"><div class="line">&gt; cmake --build . -- install</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md10"></a>
Usage</h1>
<h2><a class="anchor" id="autotoc_md11"></a>
Generating data</h2>
<p>The repository comes with a Python3 script (in the <code>utility_scripts/</code> directory) to simply generate arbitrarily large data sets.</p>
<p>In order to use all functionality, the following Python3 modules must be installed: <a href="https://docs.python.org/3/library/argparse.html"><code>argparse</code></a>, <a href="https://docs.python.org/3/library/timeit.html"><code>timeit</code></a>, <a href="https://pypi.org/project/numpy/"><code>numpy</code></a>, <a href="https://pypi.org/project/pandas/"><code>pandas</code></a>, <a href="https://scikit-learn.org/stable/"><code>sklearn</code></a>, <a href="https://pypi.org/project/arff/"><code>arff</code></a>, <a href="https://pypi.org/project/matplotlib/"><code>matplotlib</code></a> and <a href="https://pypi.org/project/matplotlib/"><code>mpl_toolkits</code></a></p>
<div class="fragment"><div class="line">&gt; python3 utility_scripts/generate_data**.py --help</div>
<div class="line">usage: generate_data.py [-h] --output OUTPUT --format FORMAT [--problem PROBLEM] --samples SAMPLES [--test_samples TEST_SAMPLES] --features FEATURES [--plot]</div>
<div class="line"> </div>
<div class="line">optional arguments:</div>
<div class="line">  -h, --help            show this help message and exit</div>
<div class="line">  --output OUTPUT       the output file to write the samples to (without extension)</div>
<div class="line">  --format FORMAT       the file format; either arff or libsvm</div>
<div class="line">  --problem PROBLEM     the problem to solve; one of: blobs, blobs_merged, planes, planes_merged, ball</div>
<div class="line">  --samples SAMPLES     the number of training samples to generate</div>
<div class="line">  --test_samples TEST_SAMPLES</div>
<div class="line">                        the number of test samples to generate; default: 0</div>
<div class="line">  --features FEATURES   the number of features per data point</div>
<div class="line">  --plot                plot training samples; only possible if 0 &lt; samples &lt;= 2000 and 1 &lt; features &lt;= 3</div>
</div><!-- fragment --><p>An example invocation generating a data set consisting of blobs with 1000 data points with 200 features each could look like:</p>
<div class="fragment"><div class="line">&gt; python3 generate_data.py --ouput data_file --format libsvm --problem blobs --samples 1000 --features 200</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md12"></a>
Training</h2>
<div class="fragment"><div class="line">&gt; ./svm-train --help</div>
<div class="line">LS-SVM with multiple (GPU-)backends</div>
<div class="line">Usage:</div>
<div class="line">  ./svm-train [OPTION...] training_set_file [model_file]</div>
<div class="line"> </div>
<div class="line">  -t, --kernel_type arg         set type of kernel function.</div>
<div class="line">                                         0 -- linear: u&#39;*v</div>
<div class="line">                                         1 -- polynomial: (gamma*u&#39;*v + coef0)^degree</div>
<div class="line">                                         2 -- radial basis function: exp(-gamma*|u-v|^2) (default: 0)</div>
<div class="line">  -d, --degree arg              set degree in kernel function (default: 3)</div>
<div class="line">  -g, --gamma arg               set gamma in kernel function (default: 1 / num_features)</div>
<div class="line">  -r, --coef0 arg               set coef0 in kernel function (default: 0)</div>
<div class="line">  -c, --cost arg                set the parameter C (default: 1)</div>
<div class="line">  -e, --epsilon arg             set the tolerance of termination criterion (default: 0.001)</div>
<div class="line">  -b, --backend arg             choose the backend: openmp|cuda|opencl|sycl (default: openmp)</div>
<div class="line">  -p, --target_platform arg     choose the target platform: automatic|cpu|gpu_nvidia|gpu_amd|gpu_intel (default: automatic)</div>
<div class="line">  -q, --quiet                   quiet mode (no outputs)</div>
<div class="line">  -h, --help                    print this helper message</div>
<div class="line">      --input training_set_file</div>
<div class="line"> </div>
<div class="line">      --model model_file</div>
</div><!-- fragment --><p>An example invocation using the CUDA backend could look like:</p>
<div class="fragment"><div class="line">&gt; ./svm-train --backend cuda --input /path/to/data_file</div>
</div><!-- fragment --><p>Another example targeting NVIDIA GPUs using the SYCL backend looks like:</p>
<div class="fragment"><div class="line">&gt; ./svm-train --backend sycl --target_platform gpu_nvidia --input /path/to/data_file</div>
</div><!-- fragment --><p>The <code>--target_platform=automatic</code> flags works for the different backends as follows:</p>
<ul>
<li><code>OpenMP</code>: always selects a CPU</li>
<li><code>CUDA</code>: always selects an NVIDIA GPU (if no NVIDIA GPU is available, throws an exception)</li>
<li><code>OpenCL</code>: tries to find available devices in the following order: NVIDIA GPUs 🠦 AMD GPUs 🠦 Intel GPUs 🠦 CPU</li>
<li><code>SYCL</code>: tries to find available devices in the following order: NVIDIA GPUs 🠦 AMD GPUs 🠦 Intel GPUs 🠦 CPU</li>
</ul>
<h2><a class="anchor" id="autotoc_md13"></a>
Predicting</h2>
<div class="fragment"><div class="line">&gt; ./svm-predict --help</div>
<div class="line">LS-SVM with multiple (GPU-)backends</div>
<div class="line">Usage:</div>
<div class="line">  ./svm-predict [OPTION...] test_file model_file [output_file]</div>
<div class="line"> </div>
<div class="line">  -b, --backend arg          choose the backend: openmp|cuda|opencl|sycl (default: openmp)</div>
<div class="line">  -p, --target_platform arg  choose the target platform: automatic|cpu|gpu_nvidia|gpu_amd|gpu_intel (default: automatic)</div>
<div class="line">  -q, --quiet                quiet mode (no outputs)</div>
<div class="line">  -h, --help                 print this helper message</div>
<div class="line">      --test test_file</div>
<div class="line">      --model model_file</div>
<div class="line">      --output output_file</div>
</div><!-- fragment --><p>An example invocation could look like:</p>
<div class="fragment"><div class="line">&gt; ./svm-predict --backend cuda --test /path/to/test_file --model /path/to/model_file</div>
</div><!-- fragment --><p>Another example targeting NVIDIA GPUs using the SYCL backend looks like:</p>
<div class="fragment"><div class="line">&gt; ./svm-predict --backend sycl --target_platform gpu_nvidia --test /path/to/test_file --model /path/to/model_file</div>
</div><!-- fragment --><p>The <code>--target_platform=automatic</code> flags works like in the training (<code>./svm-train</code>) case.</p>
<h1><a class="anchor" id="autotoc_md14"></a>
Example code for usage as library</h1>
<p>A simple C++ program (<code>main.cpp</code>) using this library could look like:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="core_8hpp.html">plssvm/core.hpp</a>&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &lt;exception&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> main(i) {</div>
<div class="line">    <span class="keywordflow">try</span> {</div>
<div class="line">        <span class="comment">// parse SVM parameter from command line</span></div>
<div class="line">        <a class="code" href="classplssvm_1_1parameter.html">plssvm::parameter&lt;double&gt;</a> params;</div>
<div class="line">        params.<a class="code" href="classplssvm_1_1parameter.html#a002f0530bdb2a5e62cf4bf2111db5494">backend</a> = <a class="code" href="namespaceplssvm.html#abdb476fa824886f6d3ec438d86579c70a39466fe22b062a34cfe09f3cc8c24868">plssvm::backend_type::cuda</a>;</div>
<div class="line"> </div>
<div class="line">        params.<a class="code" href="classplssvm_1_1parameter.html#aa1bc08848934c1f38c2fd3d982b97ea3">parse_train_file</a>(<span class="stringliteral">&quot;train_file.libsvm&quot;</span>);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// create C-SVM (based on selected backend)</span></div>
<div class="line">        <span class="keyword">auto</span> svm = <a class="code" href="namespaceplssvm.html#ad170b84d08afc8714fd1eb4bec4ff49d">plssvm::make_csvm</a>(params);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// learn</span></div>
<div class="line">        svm-&gt;learn();</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// get accuracy</span></div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;accuracy: &quot;</span> &lt;&lt; svm-&gt;accuracy() &lt;&lt; std::endl;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// predict</span></div>
<div class="line">        std::vector&lt;double&gt; point = { ... };</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;label: &quot;</span> &lt;&lt; svm-&gt;predict(point) &lt;&lt; std::endl;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// write model file to disk</span></div>
<div class="line">        svm-&gt;write_model(<span class="stringliteral">&quot;model_file.libsvm&quot;</span>);</div>
<div class="line">    } <span class="keywordflow">catch</span> (<span class="keyword">const</span> <a class="code" href="classplssvm_1_1exception.html">plssvm::exception</a> &amp;e) {</div>
<div class="line">        std::cerr &lt;&lt; e.<a class="code" href="classplssvm_1_1exception.html#ae801b36bcd872f2557e813b5f20aae58">what_with_loc</a>() &lt;&lt; std::endl;</div>
<div class="line">    } <span class="keywordflow">catch</span> (<span class="keyword">const</span> std::exception &amp;e) {</div>
<div class="line">        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
<div class="ttc" id="aclassplssvm_1_1exception_html"><div class="ttname"><a href="classplssvm_1_1exception.html">plssvm::exception</a></div><div class="ttdoc">Base class for all custom exception types. Forwards its message to std::runtime_error and saves the e...</div><div class="ttdef"><b>Definition:</b> exceptions.hpp:26</div></div>
<div class="ttc" id="aclassplssvm_1_1exception_html_ae801b36bcd872f2557e813b5f20aae58"><div class="ttname"><a href="classplssvm_1_1exception.html#ae801b36bcd872f2557e813b5f20aae58">plssvm::exception::what_with_loc</a></div><div class="ttdeci">std::string what_with_loc() const</div><div class="ttdoc">Returns a sting containing the exception's what() message, the name of the thrown exception class and...</div></div>
<div class="ttc" id="aclassplssvm_1_1parameter_html"><div class="ttname"><a href="classplssvm_1_1parameter.html">plssvm::parameter</a></div><div class="ttdoc">Base class for encapsulating all necessary parameters possibly provided through command line argument...</div><div class="ttdef"><b>Definition:</b> parameter.hpp:31</div></div>
<div class="ttc" id="aclassplssvm_1_1parameter_html_a002f0530bdb2a5e62cf4bf2111db5494"><div class="ttname"><a href="classplssvm_1_1parameter.html#a002f0530bdb2a5e62cf4bf2111db5494">plssvm::parameter::backend</a></div><div class="ttdeci">backend_type backend</div><div class="ttdoc">The used backend: OpenMP, OpenCL, CUDA, or SYCL.</div><div class="ttdef"><b>Definition:</b> parameter.hpp:190</div></div>
<div class="ttc" id="aclassplssvm_1_1parameter_html_aa1bc08848934c1f38c2fd3d982b97ea3"><div class="ttname"><a href="classplssvm_1_1parameter.html#aa1bc08848934c1f38c2fd3d982b97ea3">plssvm::parameter::parse_train_file</a></div><div class="ttdeci">void parse_train_file(const std::string &amp;filename)</div><div class="ttdoc">Parse the given file as training data. If the file is in the arff format (has the ....</div></div>
<div class="ttc" id="acore_8hpp_html"><div class="ttname"><a href="core_8hpp.html">core.hpp</a></div><div class="ttdoc">Core header including all other necessary headers.</div></div>
<div class="ttc" id="anamespaceplssvm_html_abdb476fa824886f6d3ec438d86579c70a39466fe22b062a34cfe09f3cc8c24868"><div class="ttname"><a href="namespaceplssvm.html#abdb476fa824886f6d3ec438d86579c70a39466fe22b062a34cfe09f3cc8c24868">plssvm::backend_type::cuda</a></div><div class="ttdeci">@ cuda</div></div>
<div class="ttc" id="anamespaceplssvm_html_ad170b84d08afc8714fd1eb4bec4ff49d"><div class="ttname"><a href="namespaceplssvm.html#ad170b84d08afc8714fd1eb4bec4ff49d">plssvm::make_csvm</a></div><div class="ttdeci">std::unique_ptr&lt; csvm&lt; T &gt; &gt; make_csvm(const parameter&lt; T &gt; &amp;params)</div><div class="ttdoc">Construct a new C-SVM with the parameters given through params using the requested backend.</div><div class="ttdef"><b>Definition:</b> csvm_factory.hpp:45</div></div>
</div><!-- fragment --><p>With a corresponding minimal CMake file:</p>
<div class="fragment"><div class="line">cmake_minimum_required(VERSION 3.16)</div>
<div class="line"> </div>
<div class="line">project(LibraryUsageExample</div>
<div class="line">        LANGUAGES CXX)</div>
<div class="line"> </div>
<div class="line">find_package(plssvm CONFIG REQUIRED)</div>
<div class="line"> </div>
<div class="line">add_executable(prog main.cpp)</div>
<div class="line"> </div>
<div class="line">target_compile_features(prog PUBLIC cxx_std_17)</div>
<div class="line">target_link_libraries(prog PUBLIC plssvm::svm-all)</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md15"></a>
License</h1>
<p>The PLSSVM library is distributed under the MIT <a href="https://github.com/SC-SGS/PLSSVM/blob/main/LICENSE.md">license</a>. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed Jan 19 2022 16:43:40 for PLSSVM - Parallel Least-Squares Support Vector Machine by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
