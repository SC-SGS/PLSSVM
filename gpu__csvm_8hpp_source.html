<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>PLSSVM - Parallel Least Squares Support Vector Machine: include/plssvm/backends/gpu_csvm.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo_90x55.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">PLSSVM - Parallel Least Squares Support Vector Machine
   &#160;<span id="projectnumber">2.0.0</span>
   </div>
   <div id="projectbrief">A Least Squares Support Vector Machine implementation using different backends.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_9696d1624c88fbb4b2358edab2255cb6.html">plssvm</a></li><li class="navelem"><a class="el" href="dir_aece132851e9183324b9b3740ef79635.html">backends</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">gpu_csvm.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="gpu__csvm_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160; </div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#ifndef PLSSVM_BACKENDS_GPU_CSVM_HPP_</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#define PLSSVM_BACKENDS_GPU_CSVM_HPP_</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#pragma once</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160; </div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="constants_8hpp.html">plssvm/constants.hpp</a>&quot;</span>                   <span class="comment">// plssvm::{THREAD_BLOCK_SIZE, INTERNAL_BLOCK_SIZE}</span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="csvm_8hpp.html">plssvm/csvm.hpp</a>&quot;</span>                        <span class="comment">// plssvm::csvm</span></div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="execution__range_8hpp.html">plssvm/detail/execution_range.hpp</a>&quot;</span>      <span class="comment">// plssvm::detail::execution_range</span></div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="layout_8hpp.html">plssvm/detail/layout.hpp</a>&quot;</span>               <span class="comment">// plssvm::detail::{transform_to_layout, layout_type}</span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="logger_8hpp.html">plssvm/detail/logger.hpp</a>&quot;</span>               <span class="comment">// plssvm::detail::log, plssvm::verbosity_level</span></div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="performance__tracker_8hpp.html">plssvm/detail/performance_tracker.hpp</a>&quot;</span>  <span class="comment">// plssvm::detail::tracking_entry, PLSSVM_DETAIL_PERFORMANCE_TRACKER_ADD_TRACKING_ENTRY</span></div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="parameter_8hpp.html">plssvm/parameter.hpp</a>&quot;</span>                   <span class="comment">// plssvm::parameter</span></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160; </div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#include &quot;fmt/chrono.h&quot;</span>                           <span class="comment">// output std::chrono times using {fmt}</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#include &quot;fmt/core.h&quot;</span>                             <span class="comment">// fmt::format</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160; </div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="preprocessor">#include &lt;algorithm&gt;</span>                              <span class="comment">// std::min, std::all_of, std::adjacent_find</span></div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#include &lt;chrono&gt;</span>                                 <span class="comment">// std::chrono::{milliseconds, steady_clock, duration_cast}</span></div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#include &lt;cmath&gt;</span>                                  <span class="comment">// std::ceil</span></div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#include &lt;cstddef&gt;</span>                                <span class="comment">// std::size_t</span></div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#include &lt;functional&gt;</span>                             <span class="comment">// std::less_equal</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="preprocessor">#include &lt;iostream&gt;</span>                               <span class="comment">// std::clog, std::cout, std::endl</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="preprocessor">#include &lt;tuple&gt;</span>                                  <span class="comment">// std::tuple, std::make_tuple</span></div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span>                                <span class="comment">// std::forward, std::pair, std::move, std::make_pair</span></div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span>                                 <span class="comment">// std::vector</span></div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160; </div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespaceplssvm_1_1detail.html">plssvm::detail</a> {</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160; </div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> device_ptr_t, <span class="keyword">typename</span> queue_t&gt;</div>
<div class="line"><a name="l00046"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html">   46</a></span>&#160;<span class="keyword">class </span><a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html">gpu_csvm</a> : <span class="keyword">public</span> <a class="code" href="classplssvm_1_1csvm.html">::plssvm::csvm</a> {</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;  <span class="keyword">public</span>:</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">   50</a></span>&#160;    <span class="keyword">using</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type</a> = device_ptr_t&lt;real_type&gt;;</div>
<div class="line"><a name="l00052"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a854274fb062a44d7c6db3d79ffdc51b4">   52</a></span>&#160;    <span class="keyword">using</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a854274fb062a44d7c6db3d79ffdc51b4">queue_type</a> = queue_t;</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160; </div>
<div class="line"><a name="l00057"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a9994493993fd1359c7bf37d54572487f">   57</a></span>&#160;    <span class="keyword">explicit</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a9994493993fd1359c7bf37d54572487f">gpu_csvm</a>(<a class="code" href="structplssvm_1_1detail_1_1parameter.html">plssvm::parameter</a> params = {}) :</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;        ::<a class="code" href="classplssvm_1_1csvm.html">plssvm::csvm</a>{ params } {}</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span>... Args&gt;</div>
<div class="line"><a name="l00065"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a96686349358b90d2961bfa86fb65c307">   65</a></span>&#160;    <span class="keyword">explicit</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a96686349358b90d2961bfa86fb65c307">gpu_csvm</a>(Args &amp;&amp;...args) :</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;        ::<a class="code" href="namespaceplssvm.html">plssvm</a>::<a class="code" href="classplssvm_1_1csvm.html">csvm</a>{ std::forward&lt;Args&gt;(args)... } {}</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160; </div>
<div class="line"><a name="l00071"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a233b832ed6fc5991d888a8f96e1d1216">   71</a></span>&#160;    <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a233b832ed6fc5991d888a8f96e1d1216">gpu_csvm</a>(<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html">gpu_csvm</a> &amp;) = <span class="keyword">delete</span>;</div>
<div class="line"><a name="l00075"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#ab3eaa72ddf8ff84c36878be5a935229b">   75</a></span>&#160;    <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#ab3eaa72ddf8ff84c36878be5a935229b">gpu_csvm</a>(<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html">gpu_csvm</a> &amp;&amp;) noexcept = default;</div>
<div class="line"><a name="l00079"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a9f8c81d28cf483d0e06b3d8c901465c7">   79</a></span>&#160;    <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html">gpu_csvm</a> &amp;operator=(const <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html">gpu_csvm</a> &amp;) = delete;</div>
<div class="line"><a name="l00083"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a99d13a7f7197ee199f7a20adb5e13e32">   83</a></span>&#160;    <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html">gpu_csvm</a> &amp;operator=(<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html">gpu_csvm</a> &amp;&amp;) noexcept = default;</div>
<div class="line"><a name="l00087"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#af0a1078f8d2182174e1c226c036c518c">   87</a></span>&#160;    ~<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html">gpu_csvm</a>() override = default;</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160; </div>
<div class="line"><a name="l00093"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#abe6edfd2cb23cdd1e54a98ad42116ccd">   93</a></span>&#160;    [[nodiscard]] std::<span class="keywordtype">size_t</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#abe6edfd2cb23cdd1e54a98ad42116ccd">num_available_devices</a>() const noexcept {</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a723115a038e518d4a1ec37bc0fa8b434">devices_</a>.size();</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;    }</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160; </div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;  <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00101"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a44b7af7e1903ddab1e06348b659a65d3">  101</a></span>&#160;    [[nodiscard]] std::pair&lt;std::vector&lt;float&gt;, <span class="keywordtype">float</span>&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a44b7af7e1903ddab1e06348b659a65d3">solve_system_of_linear_equations</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;float&gt;</a> &amp;params, <span class="keyword">const</span> std::vector&lt;std::vector&lt;float&gt;&gt; &amp;A, std::vector&lt;float&gt; b, <span class="keywordtype">float</span> eps, <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <span class="keywordtype">long</span> max_iter) <span class="keyword">const</span> <span class="keyword">final</span> { <span class="keywordflow">return</span> this-&gt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af771eb7c749984ff0257b48c42236866">solve_system_of_linear_equations_impl</a>(params, A, std::move(b), eps, max_iter); }</div>
<div class="line"><a name="l00105"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a8b1935a343bfab1504dd1e99ff1e12b4">  105</a></span>&#160;    [[nodiscard]] std::pair&lt;std::vector&lt;double&gt;, <span class="keywordtype">double</span>&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a8b1935a343bfab1504dd1e99ff1e12b4">solve_system_of_linear_equations</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;double&gt;</a> &amp;params, <span class="keyword">const</span> std::vector&lt;std::vector&lt;double&gt;&gt; &amp;A, std::vector&lt;double&gt; b, <span class="keywordtype">double</span> eps, <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <span class="keywordtype">long</span> max_iter) <span class="keyword">const</span> <span class="keyword">final</span> { <span class="keywordflow">return</span> this-&gt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af771eb7c749984ff0257b48c42236866">solve_system_of_linear_equations_impl</a>(params, A, std::move(b), eps, max_iter); }</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00110"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#af771eb7c749984ff0257b48c42236866">  110</a></span>&#160;    [[nodiscard]] std::pair&lt;std::vector&lt;real_type&gt;, real_type&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af771eb7c749984ff0257b48c42236866">solve_system_of_linear_equations_impl</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;real_type&gt;</a> &amp;params, <span class="keyword">const</span> std::vector&lt;std::vector&lt;real_type&gt;&gt; &amp;A, std::vector&lt;real_type&gt; b, real_type eps, <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <span class="keywordtype">long</span> max_iter) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160; </div>
<div class="line"><a name="l00115"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#aae80d2f6f0fceaf06b18a2427f87a695">  115</a></span>&#160;    [[nodiscard]] std::vector&lt;float&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#aae80d2f6f0fceaf06b18a2427f87a695">predict_values</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;float&gt;</a> &amp;params, <span class="keyword">const</span> std::vector&lt;std::vector&lt;float&gt;&gt; &amp;support_vectors, <span class="keyword">const</span> std::vector&lt;float&gt; &amp;alpha, <span class="keywordtype">float</span> rho, std::vector&lt;float&gt; &amp;w, <span class="keyword">const</span> std::vector&lt;std::vector&lt;float&gt;&gt; &amp;predict_points) <span class="keyword">const</span> <span class="keyword">final</span> { <span class="keywordflow">return</span> this-&gt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#aff263192e34c8bf6342bb542bd4c05e0">predict_values_impl</a>(params, support_vectors, alpha, rho, w, predict_points); }</div>
<div class="line"><a name="l00119"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a57f8325f3de3c3f8061cfcf25eea8849">  119</a></span>&#160;    [[nodiscard]] std::vector&lt;double&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a57f8325f3de3c3f8061cfcf25eea8849">predict_values</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;double&gt;</a> &amp;params, <span class="keyword">const</span> std::vector&lt;std::vector&lt;double&gt;&gt; &amp;support_vectors, <span class="keyword">const</span> std::vector&lt;double&gt; &amp;alpha, <span class="keywordtype">double</span> rho, std::vector&lt;double&gt; &amp;w, <span class="keyword">const</span> std::vector&lt;std::vector&lt;double&gt;&gt; &amp;predict_points) <span class="keyword">const</span> <span class="keyword">final</span> { <span class="keywordflow">return</span> this-&gt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#aff263192e34c8bf6342bb542bd4c05e0">predict_values_impl</a>(params, support_vectors, alpha, rho, w, predict_points); }</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00124"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#aff263192e34c8bf6342bb542bd4c05e0">  124</a></span>&#160;    [[nodiscard]] std::vector&lt;real_type&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#aff263192e34c8bf6342bb542bd4c05e0">predict_values_impl</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;real_type&gt;</a> &amp;params, <span class="keyword">const</span> std::vector&lt;std::vector&lt;real_type&gt;&gt; &amp;support_vectors, <span class="keyword">const</span> std::vector&lt;real_type&gt; &amp;alpha, real_type rho, std::vector&lt;real_type&gt; &amp;w, <span class="keyword">const</span> std::vector&lt;std::vector&lt;real_type&gt;&gt; &amp;predict_points) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160; </div>
<div class="line"><a name="l00134"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a4365192a069366780b9ca54b5b9f49ec">  134</a></span>&#160;    [[nodiscard]] std::size_t <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a4365192a069366780b9ca54b5b9f49ec">select_num_used_devices</a>(<a class="code" href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180c">kernel_function_type</a> kernel, std::size_t num_features) <span class="keyword">const</span> noexcept;</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00147"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a66bc7ee5da121bc9ba323ae5c4c142f7">  147</a></span>&#160;    [[nodiscard]] std::tuple&lt;std::vector&lt;device_ptr_type&lt;real_type&gt;&gt;, std::vector&lt;device_ptr_type&lt;real_type&gt;&gt;, std::vector&lt;std::size_t&gt;&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a66bc7ee5da121bc9ba323ae5c4c142f7">setup_data_on_device</a>(<span class="keyword">const</span> std::vector&lt;std::vector&lt;real_type&gt;&gt; &amp;data, std::size_t num_data_points_to_setup, std::size_t num_features_to_setup, std::size_t boundary_size, std::size_t num_used_devices) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160; </div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00161"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a017cfdd2c96bd35fe0eea7645c58ddbe">  161</a></span>&#160;    [[nodiscard]] std::vector&lt;real_type&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a017cfdd2c96bd35fe0eea7645c58ddbe">generate_q</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;real_type&gt;</a> &amp;params, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;data_d, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;data_last_d, std::size_t num_data_points, <span class="keyword">const</span> std::vector&lt;std::size_t&gt; &amp;feature_ranges, std::size_t boundary_size) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00173"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a3b239311490abe7a71061a33e39b7b27">  173</a></span>&#160;    [[nodiscard]] std::vector&lt;real_type&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a3b239311490abe7a71061a33e39b7b27">calculate_w</a>(<span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;data_d, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;data_last_d, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;alpha_d, std::size_t num_data_points, <span class="keyword">const</span> std::vector&lt;std::size_t&gt; &amp;feature_ranges) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160; </div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00190"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a77085ba427ea262c212c304d77c23dca">  190</a></span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a77085ba427ea262c212c304d77c23dca">run_device_kernel</a>(std::size_t device, <span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;real_type&gt;</a> &amp;params, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;q_d, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;r_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;x_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;data_d, <span class="keyword">const</span> std::vector&lt;std::size_t&gt; &amp;feature_ranges, real_type QA_cost, real_type add, std::size_t dept, std::size_t boundary_size) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00197"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a98339d9aafdf6f12c6fc8e55ecf2728c">  197</a></span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a98339d9aafdf6f12c6fc8e55ecf2728c">device_reduction</a>(std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;buffer_d, std::vector&lt;real_type&gt; &amp;buffer) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160; </div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;    <span class="comment">//*************************************************************************************************************************************//</span></div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;    <span class="comment">//                                         pure virtual, must be implemented by all subclasses                                         //</span></div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;    <span class="comment">//*************************************************************************************************************************************//</span></div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;    <span class="comment">// Note: there are two versions of each function (one for float and one for double) since virtual template functions are not allowed in C++!</span></div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160; </div>
<div class="line"><a name="l00208"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a769c736ee34f4511527264b4365ea9b6">  208</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a769c736ee34f4511527264b4365ea9b6">device_synchronize</a>(<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a854274fb062a44d7c6db3d79ffdc51b4">queue_type</a> &amp;queue) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l00220"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#ab2145facc80b430d141a00918f0ffa38">  220</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#ab2145facc80b430d141a00918f0ffa38">run_q_kernel</a>(std::size_t device, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> &amp;range, <span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;float&gt;</a> &amp;params, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;q_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;data_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;data_last_d, std::size_t num_data_points_padded, std::size_t num_features) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l00224"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#adfb40de23ed08e603e6ffdb9c16a432b">  224</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#adfb40de23ed08e603e6ffdb9c16a432b">run_q_kernel</a>(std::size_t device, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> &amp;range, <span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;double&gt;</a> &amp;params, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;q_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;data_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;data_last_d, std::size_t num_data_points_padded, std::size_t num_features) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l00239"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a7e47a0051022376215b07ea43799df2d">  239</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a7e47a0051022376215b07ea43799df2d">run_svm_kernel</a>(std::size_t device, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> &amp;range, <span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;float&gt;</a> &amp;params, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;q_d, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;r_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;x_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;data_d, <span class="keywordtype">float</span> QA_cost, <span class="keywordtype">float</span> add, std::size_t num_data_points_padded, std::size_t num_features) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l00243"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#afb6d0b23bf3292f2652442ca83004342">  243</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#afb6d0b23bf3292f2652442ca83004342">run_svm_kernel</a>(std::size_t device, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> &amp;range, <span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;double&gt;</a> &amp;params, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;q_d, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;r_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;x_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;data_d, <span class="keywordtype">double</span> QA_cost, <span class="keywordtype">double</span> add, std::size_t num_data_points_padded, std::size_t num_features) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l00255"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#abd61c52c8399dc50ac0a648e02e2c887">  255</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#abd61c52c8399dc50ac0a648e02e2c887">run_w_kernel</a>(std::size_t device, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> &amp;range, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;w_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;alpha_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;data_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;data_last_d, std::size_t num_data_points, std::size_t num_features) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l00259"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a85b5b858884716aeb01f707839fadb0f">  259</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a85b5b858884716aeb01f707839fadb0f">run_w_kernel</a>(std::size_t device, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> &amp;range, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;w_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;alpha_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;data_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;data_last_d, std::size_t num_data_points, std::size_t num_features) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l00273"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#aa11267c182956dd778892d92d015bfb1">  273</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#aa11267c182956dd778892d92d015bfb1">run_predict_kernel</a>(<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> &amp;range, <span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;float&gt;</a> &amp;params, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;out_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;alpha_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;point_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;data_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;float&gt;</a> &amp;data_last_d, std::size_t num_support_vectors, std::size_t num_predict_points, std::size_t num_features) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l00277"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#aeccf974410597aa594c09087d8284aa4">  277</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#aeccf974410597aa594c09087d8284aa4">run_predict_kernel</a>(<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> &amp;range, <span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;double&gt;</a> &amp;params, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;out_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;alpha_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;point_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;data_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;double&gt;</a> &amp;data_last_d, std::size_t num_support_vectors, std::size_t num_predict_points, std::size_t num_features) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160; </div>
<div class="line"><a name="l00280"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a723115a038e518d4a1ec37bc0fa8b434">  280</a></span>&#160;    std::vector&lt;queue_type&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a723115a038e518d4a1ec37bc0fa8b434">devices_</a>{};</div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;};</div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160; </div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> device_ptr_t, <span class="keyword">typename</span> queue_t&gt;</div>
<div class="line"><a name="l00284"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a4365192a069366780b9ca54b5b9f49ec">  284</a></span>&#160;std::size_t <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a4365192a069366780b9ca54b5b9f49ec">gpu_csvm&lt;device_ptr_t, queue_t&gt;::select_num_used_devices</a>(<span class="keyword">const</span> <a class="code" href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180c">kernel_function_type</a> kernel, <span class="keyword">const</span> std::size_t num_features) <span class="keyword">const</span> noexcept {</div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(num_features &gt; 0, <span class="stringliteral">&quot;At lest one feature must be given!&quot;</span>);</div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160; </div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;    <span class="comment">// polynomial and rbf kernel currently only support single GPU execution</span></div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;    <span class="keywordflow">if</span> ((kernel == <a class="code" href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180ca89693d3333328e76f4fdeed379e8f9ea">kernel_function_type::polynomial</a> || kernel == <a class="code" href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180ca1c2fc056f2b0d4685d95adb8764a3912">kernel_function_type::rbf</a>) &amp;&amp; devices_.size() &gt; 1) {</div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;        std::clog &lt;&lt; fmt::format(<span class="stringliteral">&quot;Warning: found {} devices, however only 1 device can be used since the polynomial and rbf kernels currently only support single GPU execution!&quot;</span>, devices_.size()) &lt;&lt; std::endl;</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;        <span class="keywordflow">return</span> 1;</div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;    }</div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160; </div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;    <span class="comment">// the number of used devices may not exceed the number of features</span></div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;    <span class="keyword">const</span> std::size_t num_used_devices = std::min(devices_.size(), num_features);</div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;    <span class="keywordflow">if</span> (num_used_devices &lt; devices_.size()) {</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;        std::clog &lt;&lt; fmt::format(<span class="stringliteral">&quot;Warning: found {} devices, however only {} device(s) can be used since the data set only has {} features!&quot;</span>, devices_.size(), num_used_devices, num_features) &lt;&lt; std::endl;</div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;    }</div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;    <span class="keywordflow">return</span> num_used_devices;</div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;}</div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160; </div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> device_ptr_t, <span class="keyword">typename</span> queue_t&gt;</div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;std::tuple&lt;std::vector&lt;device_ptr_t&lt;real_type&gt;&gt;, std::vector&lt;device_ptr_t&lt;real_type&gt;&gt;, std::vector&lt;std::size_t&gt;&gt;</div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a66bc7ee5da121bc9ba323ae5c4c142f7">gpu_csvm&lt;device_ptr_t, queue_t&gt;::setup_data_on_device</a>(<span class="keyword">const</span> std::vector&lt;std::vector&lt;real_type&gt;&gt; &amp;data,</div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;                                                      <span class="keyword">const</span> std::size_t num_data_points_to_setup,</div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;                                                      <span class="keyword">const</span> std::size_t num_features_to_setup,</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;                                                      <span class="keyword">const</span> std::size_t boundary_size,</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;                                                      <span class="keyword">const</span> std::size_t num_used_devices)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!data.empty(), <span class="stringliteral">&quot;The data must not be empty!&quot;</span>);</div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!data.front().empty(), <span class="stringliteral">&quot;The data points must contain at least one feature!&quot;</span>);</div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(data.cbegin(), data.cend(), [&amp;data](<span class="keyword">const</span> std::vector&lt;real_type&gt; &amp;data_point) { return data_point.size() == data.front().size(); }), <span class="stringliteral">&quot;All data points must have the same number of features!&quot;</span>);</div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(num_data_points_to_setup &gt; 0, <span class="stringliteral">&quot;At least one data point must be copied to the device!&quot;</span>);</div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(num_data_points_to_setup &lt;= data.size(), <span class="stringliteral">&quot;Can&#39;t copy more data points to the device than are present!: {} &lt;= {}&quot;</span>, num_data_points_to_setup, data.size());</div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(num_features_to_setup &gt; 0, <span class="stringliteral">&quot;At least one feature must be copied to the device!&quot;</span>);</div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(num_features_to_setup &lt;= data.front().size(), <span class="stringliteral">&quot;Can&#39;t copy more features to the device than are present!: {} &lt;= {}&quot;</span>, num_features_to_setup, data.front().size());</div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(num_used_devices &lt;= devices_.size(), <span class="stringliteral">&quot;Can&#39;t use more devices than are available!: {} &lt;= {}&quot;</span>, num_used_devices, devices_.size());</div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160; </div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;    <span class="comment">// calculate the number of features per device</span></div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;    std::vector&lt;std::size_t&gt; feature_ranges(num_used_devices + 1);</div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt;= num_used_devices; ++device) {</div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;        feature_ranges[device] = device * num_features_to_setup / num_used_devices;</div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;    }</div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160; </div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;    <span class="comment">// transform 2D to 1D SoA data</span></div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;    <span class="keyword">const</span> std::vector&lt;real_type&gt; transformed_data = <a class="code" href="namespaceplssvm_1_1detail.html#ae3035abd433eac136aaa8381d80adc7f">detail::transform_to_layout</a>(<a class="code" href="namespaceplssvm_1_1detail.html#ae892fe94f0993706ca5a964c6113e274aa39d8591483b67fb637bb445f9f4f059">detail::layout_type::soa</a>, data, boundary_size, num_data_points_to_setup);</div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160; </div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; data_last_d(num_used_devices);</div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; data_d(num_used_devices);</div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160; </div>
<div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;<span class="preprocessor">    #pragma omp parallel for default(none) shared(num_used_devices, devices_, feature_ranges, data_last_d, data_d, data, transformed_data) firstprivate(num_data_points_to_setup, boundary_size, num_features_to_setup)</span></div>
<div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;        <span class="keyword">const</span> std::size_t num_features_in_range = feature_ranges[device + 1] - feature_ranges[device];</div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160; </div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;        <span class="comment">// initialize data_last on device</span></div>
<div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;        data_last_d[device] = device_ptr_type&lt;real_type&gt;{ num_features_in_range + boundary_size, devices_[device] };</div>
<div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;        data_last_d[device].memset(0);</div>
<div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;        data_last_d[device].copy_to_device(data.back().data() + feature_ranges[device], 0, num_features_in_range);</div>
<div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160; </div>
<div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;        <span class="keyword">const</span> std::size_t device_data_size = num_features_in_range * (num_data_points_to_setup + boundary_size);</div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;        data_d[device] = device_ptr_type&lt;real_type&gt;{ device_data_size, devices_[device] };</div>
<div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;        data_d[device].copy_to_device(transformed_data.data() + feature_ranges[device] * (num_data_points_to_setup + boundary_size), 0, device_data_size);</div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;    }</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160; </div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;    <span class="keywordflow">return</span> std::make_tuple(std::move(data_d), std::move(data_last_d), std::move(feature_ranges));</div>
<div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;}</div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160; </div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> device_ptr_t, <span class="keyword">typename</span> queue_t&gt;</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00351"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a017cfdd2c96bd35fe0eea7645c58ddbe">  351</a></span>&#160;std::vector&lt;real_type&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a017cfdd2c96bd35fe0eea7645c58ddbe">gpu_csvm&lt;device_ptr_t, queue_t&gt;::generate_q</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;real_type&gt;</a> &amp;params,</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;                                                                   <span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;data_d,</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;                                                                   <span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;data_last_d,</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;                                                                   <span class="keyword">const</span> std::size_t num_data_points,</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;                                                                   <span class="keyword">const</span> std::vector&lt;std::size_t&gt; &amp;feature_ranges,</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;                                                                   <span class="keyword">const</span> std::size_t boundary_size)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!data_d.empty(), <span class="stringliteral">&quot;The data_d array may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(data_d.cbegin(), data_d.cend(), [](<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;ptr) { return !ptr.empty(); }), <span class="stringliteral">&quot;Each device_ptr in data_d must at least contain one data point!&quot;</span>);</div>
<div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!data_last_d.empty(), <span class="stringliteral">&quot;The data_last_d array may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(data_last_d.cbegin(), data_last_d.cend(), [](<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;ptr) { return !ptr.empty(); }), <span class="stringliteral">&quot;Each device_ptr in data_last_d must at least contain one data point!&quot;</span>);</div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(data_d.size() == data_last_d.size(), <span class="stringliteral">&quot;The number of used devices to the data_d and data_last_d vectors must be equal!: {} != {}&quot;</span>, data_d.size(), data_last_d.size());</div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(num_data_points &gt; 0, <span class="stringliteral">&quot;At least one data point must be used to calculate q!&quot;</span>);</div>
<div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(feature_ranges.size() == data_d.size() + 1, <span class="stringliteral">&quot;The number of values in the feature_range vector must be exactly one more than the number of used devices!: {} != {} + 1&quot;</span>, feature_ranges.size(), data_d.size());</div>
<div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::adjacent_find(feature_ranges.cbegin(), feature_ranges.cend(), std::less_equal&lt;&gt;{}) != feature_ranges.cend(), <span class="stringliteral">&quot;The feature ranges are not monotonically increasing!&quot;</span>);</div>
<div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160; </div>
<div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;    <span class="keyword">const</span> std::size_t num_used_devices = data_d.size();</div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; q_d(num_used_devices);</div>
<div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160; </div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;<span class="preprocessor">    #pragma omp parallel for default(none) shared(num_used_devices, q_d, devices_, data_d, data_last_d, feature_ranges, params) firstprivate(num_data_points, boundary_size, THREAD_BLOCK_SIZE)</span></div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;        q_d[device] = <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>{ num_data_points + boundary_size, devices_[device] };</div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;        q_d[device].memset(0);</div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160; </div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;        <span class="comment">// feature splitting on multiple devices</span></div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;        <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> range({ <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(std::ceil(<span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(num_data_points) / <span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>))) },</div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;                                            { std::min&lt;std::size_t&gt;(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>, num_data_points) });</div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160; </div>
<div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;        run_q_kernel(device, range, params, q_d[device], data_d[device], data_last_d[device], num_data_points + boundary_size, feature_ranges[device + 1] - feature_ranges[device]);</div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;    }</div>
<div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160; </div>
<div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;    std::vector&lt;real_type&gt; q(num_data_points);</div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;    device_reduction(q_d, q);</div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;    <span class="keywordflow">return</span> q;</div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;}</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160; </div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> device_ptr_t, <span class="keyword">typename</span> queue_t&gt;</div>
<div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00388"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a3b239311490abe7a71061a33e39b7b27">  388</a></span>&#160;std::vector&lt;real_type&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a3b239311490abe7a71061a33e39b7b27">gpu_csvm&lt;device_ptr_t, queue_t&gt;::calculate_w</a>(<span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;data_d,</div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;                                                                    <span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;data_last_d,</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;                                                                    <span class="keyword">const</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;alpha_d,</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;                                                                    <span class="keyword">const</span> std::size_t num_data_points,</div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;                                                                    <span class="keyword">const</span> std::vector&lt;std::size_t&gt; &amp;feature_ranges)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!data_d.empty(), <span class="stringliteral">&quot;The data_d array may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(data_d.cbegin(), data_d.cend(), [](<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;ptr) { return !ptr.empty(); }), <span class="stringliteral">&quot;Each device_ptr in data_d must at least contain one data point!&quot;</span>);</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!data_last_d.empty(), <span class="stringliteral">&quot;The data_last_d array may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(data_last_d.cbegin(), data_last_d.cend(), [](<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;ptr) { return !ptr.empty(); }), <span class="stringliteral">&quot;Each device_ptr in data_last_d must at least contain one data point!&quot;</span>);</div>
<div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(data_d.size() == data_last_d.size(), <span class="stringliteral">&quot;The number of used devices to the data_d and data_last_d vectors must be equal!: {} != {}&quot;</span>, data_d.size(), data_last_d.size());</div>
<div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!alpha_d.empty(), <span class="stringliteral">&quot;The alpha_d array may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(alpha_d.cbegin(), alpha_d.cend(), [](<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;ptr) { return !ptr.empty(); }), <span class="stringliteral">&quot;Each device_ptr in alpha_d must at least contain one data point!&quot;</span>);</div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(data_d.size() == alpha_d.size(), <span class="stringliteral">&quot;The number of used devices to the data_d and alpha_d vectors must be equal!: {} != {}&quot;</span>, data_d.size(), alpha_d.size());</div>
<div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(num_data_points &gt; 0, <span class="stringliteral">&quot;At least one data point must be used to calculate q!&quot;</span>);</div>
<div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(feature_ranges.size() == data_d.size() + 1, <span class="stringliteral">&quot;The number of values in the feature_range vector must be exactly one more than the number of used devices!: {} != {} + 1&quot;</span>, feature_ranges.size(), data_d.size());</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::adjacent_find(feature_ranges.cbegin(), feature_ranges.cend(), std::less_equal&lt;&gt;{}) != feature_ranges.cend(), <span class="stringliteral">&quot;The feature ranges are not monotonically increasing!&quot;</span>);</div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160; </div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;    <span class="keyword">const</span> std::size_t num_used_devices = data_d.size();</div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160; </div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;    <span class="comment">// create w vector and fill with zeros</span></div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;    std::vector&lt;real_type&gt; w(feature_ranges.back(), real_type{ 0.0 });</div>
<div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160; </div>
<div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;<span class="preprocessor">    #pragma omp parallel for default(none) shared(num_used_devices, devices_, feature_ranges, alpha_d, data_d, data_last_d, w) firstprivate(num_data_points, THREAD_BLOCK_SIZE)</span></div>
<div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;        <span class="comment">// feature splitting on multiple devices</span></div>
<div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;        <span class="keyword">const</span> std::size_t num_features_in_range = feature_ranges[device + 1] - feature_ranges[device];</div>
<div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160; </div>
<div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;        <span class="comment">// create the w vector on the device</span></div>
<div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;        <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> w_d = <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>{ num_features_in_range, devices_[device] };</div>
<div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160; </div>
<div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;        <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> range({ <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(std::ceil(<span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(num_features_in_range) / <span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>))) },</div>
<div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;                                            { std::min&lt;std::size_t&gt;(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>, num_features_in_range) });</div>
<div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160; </div>
<div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;        <span class="comment">// calculate the w vector on the device</span></div>
<div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;        run_w_kernel(device, range, w_d, alpha_d[device], data_d[device], data_last_d[device], num_data_points, num_features_in_range);</div>
<div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;        <a class="code" href="namespaceplssvm_1_1cuda_1_1detail.html#a993ed255276400b7b0b1d05a66c4d78d">device_synchronize</a>(devices_[device]);</div>
<div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160; </div>
<div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;        <span class="comment">// copy back to host memory</span></div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;        w_d.copy_to_host(w.data() + feature_ranges[device], 0, num_features_in_range);</div>
<div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;    }</div>
<div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;    <span class="keywordflow">return</span> w;</div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;}</div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160; </div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> device_ptr_t, <span class="keyword">typename</span> queue_t&gt;</div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00433"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a77085ba427ea262c212c304d77c23dca">  433</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a77085ba427ea262c212c304d77c23dca">gpu_csvm&lt;device_ptr_t, queue_t&gt;::run_device_kernel</a>(<span class="keyword">const</span> std::size_t device, <span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;real_type&gt;</a> &amp;params, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;q_d, <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;r_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;x_d, <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;data_d, <span class="keyword">const</span> std::vector&lt;std::size_t&gt; &amp;feature_ranges, <span class="keyword">const</span> real_type QA_cost, <span class="keyword">const</span> real_type add, <span class="keyword">const</span> std::size_t dept, <span class="keyword">const</span> std::size_t boundary_size)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(device &lt; devices_.size(), <span class="stringliteral">&quot;Requested device {}, but only {} device(s) are available!&quot;</span>, device, devices_.size());</div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!q_d.empty(), <span class="stringliteral">&quot;The q_d device_ptr may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!r_d.empty(), <span class="stringliteral">&quot;The r_d device_ptr may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!x_d.empty(), <span class="stringliteral">&quot;The x_d device_ptr may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!data_d.empty(), <span class="stringliteral">&quot;The data_d device_ptr may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::adjacent_find(feature_ranges.cbegin(), feature_ranges.cend(), std::less_equal&lt;&gt;{}) != feature_ranges.cend(), <span class="stringliteral">&quot;The feature ranges are not monotonically increasing!&quot;</span>);</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(add == real_type{ -1.0 } || add == real_type{ 1.0 }, <span class="stringliteral">&quot;add must either by -1.0 or 1.0, but is {}!&quot;</span>, add);</div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(dept &gt; 0, <span class="stringliteral">&quot;At least one data point must be used to calculate q!&quot;</span>);</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160; </div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;    <span class="keyword">const</span> <span class="keyword">auto</span> grid = <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(std::ceil(<span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(dept) / <span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(boundary_size)));</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;    <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> range({ grid, grid }, { <a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>, <a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a> });</div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160; </div>
<div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;    run_svm_kernel(device, range, params, q_d, r_d, x_d, data_d, QA_cost, add, dept + boundary_size, feature_ranges[device + 1] - feature_ranges[device]);</div>
<div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;}</div>
<div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160; </div>
<div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> device_ptr_t, <span class="keyword">typename</span> queue_t&gt;</div>
<div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00451"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#a98339d9aafdf6f12c6fc8e55ecf2728c">  451</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#a98339d9aafdf6f12c6fc8e55ecf2728c">gpu_csvm&lt;device_ptr_t, queue_t&gt;::device_reduction</a>(std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt; &amp;buffer_d, std::vector&lt;real_type&gt; &amp;buffer)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!buffer_d.empty(), <span class="stringliteral">&quot;The buffer_d array may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(buffer_d.cbegin(), buffer_d.cend(), [](<span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> &amp;ptr) { return !ptr.empty(); }), <span class="stringliteral">&quot;Each device_ptr in buffer_d must at least contain one data point!&quot;</span>);</div>
<div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!buffer.empty(), <span class="stringliteral">&quot;The buffer array may not be empty!&quot;</span>);</div>
<div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160; </div>
<div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;    <span class="keyword">using namespace </span><a class="code" href="namespaceplssvm_1_1operators.html">plssvm::operators</a>;</div>
<div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160; </div>
<div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;    <a class="code" href="namespaceplssvm_1_1cuda_1_1detail.html#a993ed255276400b7b0b1d05a66c4d78d">device_synchronize</a>(devices_[0]);</div>
<div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;    buffer_d[0].copy_to_host(buffer, 0, buffer.size());</div>
<div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160; </div>
<div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;    <span class="keywordflow">if</span> (buffer_d.size() &gt; 1) {</div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;        std::vector&lt;real_type&gt; ret(buffer.size());</div>
<div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt;::size_type device = 1; device &lt; buffer_d.size(); ++device) {</div>
<div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;            <a class="code" href="namespaceplssvm_1_1cuda_1_1detail.html#a993ed255276400b7b0b1d05a66c4d78d">device_synchronize</a>(devices_[device]);</div>
<div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;            buffer_d[device].copy_to_host(ret, 0, ret.size());</div>
<div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160; </div>
<div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;            buffer += ret;</div>
<div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;        }</div>
<div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160; </div>
<div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;<span class="preprocessor">        #pragma omp parallel for default(none) shared(buffer_d, buffer)</span></div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;<a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>&gt;::size_type device = 0; device &lt; buffer_d.size(); ++device) {</div>
<div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;            buffer_d[device].copy_to_device(buffer, 0, buffer.size());</div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;        }</div>
<div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;    }</div>
<div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;}</div>
<div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160; </div>
<div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> device_ptr_t, <span class="keyword">typename</span> queue_t&gt;</div>
<div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00479"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#af771eb7c749984ff0257b48c42236866">  479</a></span>&#160;std::pair&lt;std::vector&lt;real_type&gt;, real_type&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af771eb7c749984ff0257b48c42236866">gpu_csvm&lt;device_ptr_t, queue_t&gt;::solve_system_of_linear_equations_impl</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;real_type&gt;</a> &amp;params,</div>
<div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;                                                                                                                    <span class="keyword">const</span> std::vector&lt;std::vector&lt;real_type&gt;&gt; &amp;A,</div>
<div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;                                                                                                                    std::vector&lt;real_type&gt; b,</div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;                                                                                                                    <span class="keyword">const</span> real_type eps,</div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;                                                                                                                    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <span class="keywordtype">long</span> max_iter)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!A.empty(), <span class="stringliteral">&quot;The data must not be empty!&quot;</span>);</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!A.front().empty(), <span class="stringliteral">&quot;The data points must contain at least one feature!&quot;</span>);</div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(A.cbegin(), A.cend(), [&amp;A](<span class="keyword">const</span> std::vector&lt;real_type&gt; &amp;data_point) { return data_point.size() == A.front().size(); }), <span class="stringliteral">&quot;All data points must have the same number of features!&quot;</span>);</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(A.size() == b.size(), <span class="stringliteral">&quot;The number of data points in the matrix A ({}) and the values in the right hand side vector ({}) must be the same!&quot;</span>, A.size(), b.size());</div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(eps &gt; real_type{ 0.0 }, <span class="stringliteral">&quot;The stopping criterion in the CG algorithm must be greater than 0.0, but is {}!&quot;</span>, eps);</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(max_iter &gt; 0, <span class="stringliteral">&quot;The number of CG iterations must be greater than 0!&quot;</span>);</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160; </div>
<div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;    <span class="keyword">using namespace </span><a class="code" href="namespaceplssvm_1_1operators.html">plssvm::operators</a>;</div>
<div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160; </div>
<div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;    <span class="keyword">const</span> std::size_t dept = A.size() - 1;</div>
<div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;    constexpr <span class="keyword">auto</span> boundary_size = <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a> * <a class="code" href="namespaceplssvm.html#ac7c75fadcf6b7f3ea0d1bb831a70933d">INTERNAL_BLOCK_SIZE</a>);</div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;    <span class="keyword">const</span> std::size_t num_features = A.front().size();</div>
<div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160; </div>
<div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;    <span class="keyword">const</span> std::size_t num_used_devices = this-&gt;select_num_used_devices(params.<a class="code" href="structplssvm_1_1detail_1_1parameter.html#af4ab7baef882761ac61a7f353ed8a655">kernel_type</a>, num_features);</div>
<div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160; </div>
<div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; data_d;</div>
<div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; data_last_d;</div>
<div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;    std::vector&lt;std::size_t&gt; feature_ranges;</div>
<div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;    std::tie(data_d, data_last_d, feature_ranges) = this-&gt;setup_data_on_device(A, dept, num_features, boundary_size, num_used_devices);</div>
<div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160; </div>
<div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;    <span class="comment">// create q vector</span></div>
<div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;    <span class="keyword">const</span> std::vector&lt;real_type&gt; q = this-&gt;generate_q(params, data_d, data_last_d, dept, feature_ranges, boundary_size);</div>
<div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160; </div>
<div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;    <span class="comment">// calculate QA_costs</span></div>
<div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;    <span class="keyword">const</span> real_type QA_cost = <a class="code" href="namespaceplssvm.html#ae76872fe47a5337ea0c783648835554d">kernel_function</a>(A.back(), A.back(), params) + real_type{ 1.0 } / params.<a class="code" href="structplssvm_1_1detail_1_1parameter.html#a338e4c74cdc29d696b611a97f4406ea7">cost</a>;</div>
<div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160; </div>
<div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;    <span class="comment">// update b</span></div>
<div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;    <span class="keyword">const</span> real_type b_back_value = b.back();</div>
<div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;    b.pop_back();</div>
<div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;    b -= b_back_value;</div>
<div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160; </div>
<div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;    std::vector&lt;real_type&gt; x(dept, 1.0);</div>
<div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; x_d(num_used_devices);</div>
<div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160; </div>
<div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;    std::vector&lt;real_type&gt; r(dept, 0.0);</div>
<div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; r_d(num_used_devices);</div>
<div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160; </div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;<span class="preprocessor">    #pragma omp parallel for default(none) shared(num_used_devices, devices_, x, x_d, r_d) firstprivate(dept, boundary_size)</span></div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;        x_d[device] = <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>{ dept + boundary_size, devices_[device] };</div>
<div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;        x_d[device].memset(0);</div>
<div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;        x_d[device].copy_to_device(x, 0, dept);</div>
<div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160; </div>
<div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;        r_d[device] = <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>{ dept + boundary_size, devices_[device] };</div>
<div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;        r_d[device].memset(0);</div>
<div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;    }</div>
<div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;    r_d[0].copy_to_device(b, 0, dept);</div>
<div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160; </div>
<div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; q_d(num_used_devices);</div>
<div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;<span class="preprocessor">    #pragma omp parallel for default(none) shared(num_used_devices, devices_, q, q_d, r_d, x_d, data_d, feature_ranges, params) firstprivate(dept, boundary_size, QA_cost, num_features)</span></div>
<div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;        q_d[device] = <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>{ dept + boundary_size, devices_[device] };</div>
<div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;        q_d[device].memset(0);</div>
<div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;        q_d[device].copy_to_device(q, 0, dept);</div>
<div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160; </div>
<div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;        <span class="comment">// r = Ax (r = b - Ax)</span></div>
<div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;        run_device_kernel(device, params, q_d[device], r_d[device], x_d[device], data_d[device], feature_ranges, QA_cost, real_type{ -1.0 }, dept, boundary_size);</div>
<div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;    }</div>
<div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;    device_reduction(r_d, r);</div>
<div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160; </div>
<div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;    <span class="comment">// delta = r.T * r</span></div>
<div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;    real_type delta = <a class="code" href="structplssvm_1_1operators_1_1transposed.html">transposed</a>{ r } * r;</div>
<div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;    <span class="keyword">const</span> real_type delta0 = delta;</div>
<div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;    std::vector&lt;real_type&gt; Ad(dept);</div>
<div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160; </div>
<div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; Ad_d(num_used_devices);</div>
<div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;        Ad_d[device] = <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>{ dept + boundary_size, devices_[device] };</div>
<div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;    }</div>
<div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160; </div>
<div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;    std::vector&lt;real_type&gt; d(r);</div>
<div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160; </div>
<div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;    <span class="comment">// timing for each CG iteration</span></div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;    std::chrono::milliseconds average_iteration_time{};</div>
<div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;    std::chrono::steady_clock::time_point iteration_start_time{};</div>
<div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;    <span class="keyword">const</span> <span class="keyword">auto</span> output_iteration_duration = [&amp;]() {</div>
<div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;        <span class="keyword">const</span> <span class="keyword">auto</span> iteration_end_time = std::chrono::steady_clock::now();</div>
<div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;        <span class="keyword">const</span> <span class="keyword">auto</span> iteration_duration = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(iteration_end_time - iteration_start_time);</div>
<div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;        <a class="code" href="namespaceplssvm_1_1detail.html#a1924673c0771230d7f653b2346578acc">detail::log</a>(<a class="code" href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741ae9dc924f238fa6cc29465942875fe8f0">verbosity_level::full</a> | <a class="code" href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741a4ad8aa3a3571ea912a6ec5ea5fdcc93c">verbosity_level::timing</a>,</div>
<div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;                    <span class="stringliteral">&quot;Done in {}.\n&quot;</span>, iteration_duration);</div>
<div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;        average_iteration_time += iteration_duration;</div>
<div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;    };</div>
<div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160; </div>
<div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;    <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <span class="keywordtype">long</span> iter = 0;</div>
<div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;    <span class="keywordflow">for</span> (; iter &lt; max_iter; ++iter) {</div>
<div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;        <a class="code" href="namespaceplssvm_1_1detail.html#a1924673c0771230d7f653b2346578acc">detail::log</a>(<a class="code" href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741ae9dc924f238fa6cc29465942875fe8f0">verbosity_level::full</a> | <a class="code" href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741a4ad8aa3a3571ea912a6ec5ea5fdcc93c">verbosity_level::timing</a>,</div>
<div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;                    <span class="stringliteral">&quot;Start Iteration {} (max: {}) with current residuum {} (target: {}). &quot;</span>, iter + 1, max_iter, delta, eps * eps * delta0);</div>
<div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;        iteration_start_time = std::chrono::steady_clock::now();</div>
<div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160; </div>
<div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;        <span class="comment">// Ad = A * r (q = A * d)</span></div>
<div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;<span class="preprocessor">        #pragma omp parallel for default(none) shared(num_used_devices, devices_, Ad_d, r_d, q_d, data_d, feature_ranges, params) firstprivate(dept, QA_cost, boundary_size, num_features)</span></div>
<div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;            Ad_d[device].memset(0);</div>
<div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;            r_d[device].memset(0, dept);</div>
<div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160; </div>
<div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;            run_device_kernel(device, params, q_d[device], Ad_d[device], r_d[device], data_d[device], feature_ranges, QA_cost, real_type{ 1.0 }, dept, boundary_size);</div>
<div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;        }</div>
<div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;        <span class="comment">// update Ad (q)</span></div>
<div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;        device_reduction(Ad_d, Ad);</div>
<div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160; </div>
<div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;        <span class="comment">// (alpha = delta_new / (d^T * q))</span></div>
<div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;        <span class="keyword">const</span> real_type alpha_cd = delta / (<a class="code" href="structplssvm_1_1operators_1_1transposed.html">transposed</a>{ d } * Ad);</div>
<div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160; </div>
<div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;        <span class="comment">// (x = x + alpha * d)</span></div>
<div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;        x += alpha_cd * d;</div>
<div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160; </div>
<div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;<span class="preprocessor">        #pragma omp parallel for default(none) shared(num_used_devices, devices_, x, x_d) firstprivate(dept)</span></div>
<div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;            x_d[device].copy_to_device(x, 0, dept);</div>
<div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;        }</div>
<div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160; </div>
<div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;        <span class="keywordflow">if</span> (iter % 50 == 49) {</div>
<div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;<span class="preprocessor">            #pragma omp parallel for default(none) shared(devices_, r_d, b, q_d, x_d, params, data_d, feature_ranges) firstprivate(QA_cost, dept)</span></div>
<div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; devices_.size(); ++device) {</div>
<div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;                <span class="keywordflow">if</span> (device == 0) {</div>
<div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;                    <span class="comment">// r = b</span></div>
<div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;                    r_d[device].copy_to_device(b, 0, dept);</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;                } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;                    <span class="comment">// set r to 0</span></div>
<div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;                    r_d[device].memset(0);</div>
<div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;                }</div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;                <span class="comment">// r -= A * x</span></div>
<div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;                run_device_kernel(device, params, q_d[device], r_d[device], x_d[device], data_d[device], feature_ranges, QA_cost, real_type{ -1.0 }, dept, boundary_size);</div>
<div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;            }</div>
<div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160; </div>
<div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;            device_reduction(r_d, r);</div>
<div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;        } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;            <span class="comment">// r -= alpha_cd * Ad (r = r - alpha * q)</span></div>
<div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;            r -= alpha_cd * Ad;</div>
<div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;        }</div>
<div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160; </div>
<div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;        <span class="comment">// (delta = r^T * r)</span></div>
<div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;        <span class="keyword">const</span> real_type delta_old = delta;</div>
<div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;        delta = <a class="code" href="structplssvm_1_1operators_1_1transposed.html">transposed</a>{ r } * r;</div>
<div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;        <span class="comment">// if we are exact enough stop CG iterations</span></div>
<div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;        <span class="keywordflow">if</span> (delta &lt;= eps * eps * delta0) {</div>
<div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;            output_iteration_duration();</div>
<div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;            <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;        }</div>
<div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160; </div>
<div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;        <span class="comment">// (beta = delta_new / delta_old)</span></div>
<div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;        <span class="keyword">const</span> real_type beta = delta / delta_old;</div>
<div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;        <span class="comment">// d = beta * d + r</span></div>
<div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;        d = beta * d + r;</div>
<div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160; </div>
<div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;        <span class="comment">// r_d = d</span></div>
<div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;<span class="preprocessor">        #pragma omp parallel for default(none) shared(num_used_devices, devices_, r_d, d) firstprivate(dept)</span></div>
<div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;            r_d[device].copy_to_device(d, 0, dept);</div>
<div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;        }</div>
<div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160; </div>
<div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;        output_iteration_duration();</div>
<div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;    }</div>
<div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;    <a class="code" href="namespaceplssvm_1_1detail.html#a1924673c0771230d7f653b2346578acc">detail::log</a>(<a class="code" href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741ae9dc924f238fa6cc29465942875fe8f0">verbosity_level::full</a> | <a class="code" href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741a4ad8aa3a3571ea912a6ec5ea5fdcc93c">verbosity_level::timing</a>,</div>
<div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;                <span class="stringliteral">&quot;Finished after {}/{} iterations with a residuum of {} (target: {}) and an average iteration time of {}.\n&quot;</span>,</div>
<div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;                <a class="code" href="structplssvm_1_1detail_1_1tracking__entry.html">detail::tracking_entry</a>{ <span class="stringliteral">&quot;cg&quot;</span>, <span class="stringliteral">&quot;iterations&quot;</span>, std::min(iter + 1, max_iter) },</div>
<div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;                <a class="code" href="structplssvm_1_1detail_1_1tracking__entry.html">detail::tracking_entry</a>{ <span class="stringliteral">&quot;cg&quot;</span>, <span class="stringliteral">&quot;max_iterations&quot;</span>, max_iter },</div>
<div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;                <a class="code" href="structplssvm_1_1detail_1_1tracking__entry.html">detail::tracking_entry</a>{ <span class="stringliteral">&quot;cg&quot;</span>, <span class="stringliteral">&quot;residuum&quot;</span>, delta },</div>
<div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;                <a class="code" href="structplssvm_1_1detail_1_1tracking__entry.html">detail::tracking_entry</a>{ <span class="stringliteral">&quot;cg&quot;</span>, <span class="stringliteral">&quot;target_residuum&quot;</span>, eps * eps * delta0 },</div>
<div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;                <a class="code" href="structplssvm_1_1detail_1_1tracking__entry.html">detail::tracking_entry</a>{ <span class="stringliteral">&quot;cg&quot;</span>, <span class="stringliteral">&quot;avg_iteration_time&quot;</span>, average_iteration_time / std::min(iter + 1, max_iter) });</div>
<div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;    <a class="code" href="performance__tracker_8hpp.html#aa68da95e449ddf405004e93907a0f7a0">PLSSVM_DETAIL_PERFORMANCE_TRACKER_ADD_TRACKING_ENTRY</a>((<a class="code" href="structplssvm_1_1detail_1_1tracking__entry.html">detail::tracking_entry</a>{ <span class="stringliteral">&quot;cg&quot;</span>, <span class="stringliteral">&quot;epsilon&quot;</span>, eps }));</div>
<div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;    <a class="code" href="namespaceplssvm_1_1detail.html#a1924673c0771230d7f653b2346578acc">detail::log</a>(<a class="code" href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741aa3cf19501138f29d2107a275e7670846">verbosity_level::libsvm</a>,</div>
<div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;                <span class="stringliteral">&quot;optimization finished, #iter = {}\n&quot;</span>, std::min(iter + 1, max_iter));</div>
<div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160; </div>
<div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;    <span class="comment">// calculate bias</span></div>
<div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;    std::vector&lt;real_type&gt; alpha(x.begin(), x.begin() + dept);</div>
<div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;    <span class="keyword">const</span> real_type bias = b_back_value + QA_cost * <a class="code" href="namespaceplssvm_1_1operators.html#a6344cb6d38f1fe59cfd7ba0f8b3382a3">sum</a>(alpha) - (<a class="code" href="structplssvm_1_1operators_1_1transposed.html">transposed</a>{ q } * alpha);</div>
<div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;    alpha.push_back(-<a class="code" href="namespaceplssvm_1_1operators.html#a6344cb6d38f1fe59cfd7ba0f8b3382a3">sum</a>(alpha));</div>
<div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160; </div>
<div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;    <span class="keywordflow">return</span> std::make_pair(std::move(alpha), -bias);</div>
<div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;}</div>
<div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160; </div>
<div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> device_ptr_t, <span class="keyword">typename</span> queue_t&gt;</div>
<div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> real_type&gt;</div>
<div class="line"><a name="l00658"></a><span class="lineno"><a class="line" href="classplssvm_1_1detail_1_1gpu__csvm.html#aff263192e34c8bf6342bb542bd4c05e0">  658</a></span>&#160;std::vector&lt;real_type&gt; <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#aff263192e34c8bf6342bb542bd4c05e0">gpu_csvm&lt;device_ptr_t, queue_t&gt;::predict_values_impl</a>(<span class="keyword">const</span> <a class="code" href="structplssvm_1_1detail_1_1parameter.html">parameter&lt;real_type&gt;</a> &amp;params,</div>
<div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;                                                                            <span class="keyword">const</span> std::vector&lt;std::vector&lt;real_type&gt;&gt; &amp;support_vectors,</div>
<div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;                                                                            <span class="keyword">const</span> std::vector&lt;real_type&gt; &amp;alpha,</div>
<div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;                                                                            real_type rho,</div>
<div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;                                                                            std::vector&lt;real_type&gt; &amp;w,</div>
<div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;                                                                            <span class="keyword">const</span> std::vector&lt;std::vector&lt;real_type&gt;&gt; &amp;predict_points)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!support_vectors.empty(), <span class="stringliteral">&quot;The support vectors must not be empty!&quot;</span>);</div>
<div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!support_vectors.front().empty(), <span class="stringliteral">&quot;The support vectors must contain at least one feature!&quot;</span>);</div>
<div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(support_vectors.cbegin(), support_vectors.cend(), [&amp;support_vectors](<span class="keyword">const</span> std::vector&lt;real_type&gt; &amp;data_point) { return data_point.size() == support_vectors.front().size(); }), <span class="stringliteral">&quot;All support vectors must have the same number of features!&quot;</span>);</div>
<div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(support_vectors.size() == alpha.size(), <span class="stringliteral">&quot;The number of support vectors ({}) and number of weights ({}) must be the same!&quot;</span>, support_vectors.size(), alpha.size());</div>
<div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(w.empty() || support_vectors.front().size() == w.size(), <span class="stringliteral">&quot;Either w must be empty or contain exactly the same number of values ({}) as features are present ({})!&quot;</span>, w.size(), support_vectors.front().size());</div>
<div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!predict_points.empty(), <span class="stringliteral">&quot;The data points to predict must not be empty!&quot;</span>);</div>
<div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(!predict_points.front().empty(), <span class="stringliteral">&quot;The data points to predict must contain at least one feature!&quot;</span>);</div>
<div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(std::all_of(predict_points.cbegin(), predict_points.cend(), [&amp;predict_points](<span class="keyword">const</span> std::vector&lt;real_type&gt; &amp;data_point) { return data_point.size() == predict_points.front().size(); }), <span class="stringliteral">&quot;All data points to predict must have the same number of features!&quot;</span>);</div>
<div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;    <a class="code" href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a>(support_vectors.front().size() == predict_points.front().size(), <span class="stringliteral">&quot;The number of features in the support vectors ({}) must be the same as in the data points to predict ({})!&quot;</span>, support_vectors.front().size(), predict_points.front().size());</div>
<div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160; </div>
<div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;    <span class="keyword">using namespace </span><a class="code" href="namespaceplssvm_1_1operators.html">plssvm::operators</a>;</div>
<div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160; </div>
<div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;    <span class="keyword">const</span> std::size_t num_support_vectors = support_vectors.size();</div>
<div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;    <span class="keyword">const</span> std::size_t num_predict_points = predict_points.size();</div>
<div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;    <span class="keyword">const</span> std::size_t num_features = predict_points.front().size();</div>
<div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;    constexpr <span class="keyword">auto</span> boundary_size = <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a> * <a class="code" href="namespaceplssvm.html#ac7c75fadcf6b7f3ea0d1bb831a70933d">INTERNAL_BLOCK_SIZE</a>);</div>
<div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160; </div>
<div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;    <span class="keyword">const</span> std::size_t num_used_devices = this-&gt;select_num_used_devices(params.<a class="code" href="structplssvm_1_1detail_1_1parameter.html#af4ab7baef882761ac61a7f353ed8a655">kernel_type</a>, num_features);</div>
<div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160; </div>
<div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;    <span class="keyword">auto</span> [data_d, data_last_d, feature_ranges] = this-&gt;setup_data_on_device(support_vectors, num_support_vectors - 1, num_features, boundary_size, num_used_devices);</div>
<div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160; </div>
<div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;    std::vector&lt;device_ptr_type&lt;real_type&gt;&gt; alpha_d(num_used_devices);</div>
<div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;<span class="preprocessor">    #pragma omp parallel for default(none) shared(num_used_devices, devices_, alpha_d, alpha) firstprivate(num_support_vectors)</span></div>
<div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;queue_type&gt;::size_type device = 0; device &lt; num_used_devices; ++device) {</div>
<div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;        alpha_d[device] = <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a>{ num_support_vectors + <a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>, devices_[device] };</div>
<div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;        alpha_d[device].memset(0);</div>
<div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;        alpha_d[device].copy_to_device(alpha, 0, num_support_vectors);</div>
<div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;    }</div>
<div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160; </div>
<div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;    std::vector&lt;real_type&gt; out(predict_points.size());</div>
<div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160; </div>
<div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;    <span class="comment">// use faster methode in case of the linear kernel function</span></div>
<div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;    <span class="keywordflow">if</span> (params.<a class="code" href="structplssvm_1_1detail_1_1parameter.html#af4ab7baef882761ac61a7f353ed8a655">kernel_type</a> == <a class="code" href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180ca9a932b3cb396238423eb2f33ec17d6aa">kernel_function_type::linear</a> &amp;&amp; w.empty()) {</div>
<div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;        w = calculate_w(data_d, data_last_d, alpha_d, support_vectors.size(), feature_ranges);</div>
<div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;    }</div>
<div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160; </div>
<div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;    <span class="keywordflow">if</span> (params.<a class="code" href="structplssvm_1_1detail_1_1parameter.html#af4ab7baef882761ac61a7f353ed8a655">kernel_type</a> == <a class="code" href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180ca9a932b3cb396238423eb2f33ec17d6aa">kernel_function_type::linear</a>) {</div>
<div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;        <span class="comment">// use faster methode in case of the linear kernel function</span></div>
<div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;<span class="preprocessor">        #pragma omp parallel for default(none) shared(out, predict_points, w) firstprivate(num_predict_points, rho)</span></div>
<div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;std::vector&lt;real_type&gt;&gt;::size_type i = 0; i &lt; num_predict_points; ++i) {</div>
<div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;            out[i] = <a class="code" href="structplssvm_1_1operators_1_1transposed.html">transposed&lt;real_type&gt;</a>{ w } * predict_points[i] + -rho;</div>
<div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;        }</div>
<div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;    } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;        <span class="comment">// create result vector on the device</span></div>
<div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;        <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> out_d{ num_predict_points + boundary_size, devices_[0] };</div>
<div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;        out_d.memset(0);</div>
<div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160; </div>
<div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;        <span class="comment">// transform prediction data</span></div>
<div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;        <span class="keyword">const</span> std::vector&lt;real_type&gt; transformed_data = <a class="code" href="namespaceplssvm_1_1detail.html#ae3035abd433eac136aaa8381d80adc7f">detail::transform_to_layout</a>(<a class="code" href="namespaceplssvm_1_1detail.html#ae892fe94f0993706ca5a964c6113e274aa39d8591483b67fb637bb445f9f4f059">detail::layout_type::soa</a>, predict_points, boundary_size, predict_points.size());</div>
<div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;        <a class="code" href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">device_ptr_type&lt;real_type&gt;</a> point_d{ num_features * (num_predict_points + boundary_size), devices_[0] };</div>
<div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;        point_d.memset(0);</div>
<div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;        point_d.copy_to_device(transformed_data, 0, transformed_data.size());</div>
<div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160; </div>
<div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;        <span class="keyword">const</span> <a class="code" href="classplssvm_1_1detail_1_1execution__range.html">detail::execution_range</a> range({ <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(std::ceil(<span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(num_support_vectors) / <span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>))),</div>
<div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;                                              <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(std::ceil(<span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(num_predict_points) / <span class="keyword">static_cast&lt;</span>real_type<span class="keyword">&gt;</span>(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>))) },</div>
<div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;                                            { std::min&lt;std::size_t&gt;(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>, num_support_vectors), std::min&lt;std::size_t&gt;(<a class="code" href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">THREAD_BLOCK_SIZE</a>, num_predict_points) });</div>
<div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160; </div>
<div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;        <span class="comment">// perform prediction on the first device</span></div>
<div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;        run_predict_kernel(range, params, out_d, alpha_d[0], point_d, data_d[0], data_last_d[0], num_support_vectors, num_predict_points, num_features);</div>
<div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160; </div>
<div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;        out_d.copy_to_host(out, 0, num_predict_points);</div>
<div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160; </div>
<div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;        <span class="comment">// add bias_ to all predictions</span></div>
<div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;        out += -rho;</div>
<div class="line"><a name="l00728"></a><span class="lineno">  728</span>&#160;    }</div>
<div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;    <span class="keywordflow">return</span> out;</div>
<div class="line"><a name="l00730"></a><span class="lineno">  730</span>&#160;}</div>
<div class="line"><a name="l00731"></a><span class="lineno">  731</span>&#160; </div>
<div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160;}  <span class="comment">// namespace plssvm::detail</span></div>
<div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160; </div>
<div class="line"><a name="l00734"></a><span class="lineno">  734</span>&#160;<span class="preprocessor">#endif  </span><span class="comment">// PLSSVM_BACKENDS_GPU_CSVM_HPP_</span></div>
<div class="ttc" id="aassert_8hpp_html_a28407e46cbc8177900a39f81512e501a"><div class="ttname"><a href="assert_8hpp.html#a28407e46cbc8177900a39f81512e501a">PLSSVM_ASSERT</a></div><div class="ttdeci">#define PLSSVM_ASSERT(cond, msg,...)</div><div class="ttdoc">Defines the PLSSVM_ASSERT macro if PLSSVM_ASSERT_ENABLED is defined.</div><div class="ttdef"><b>Definition:</b> assert.hpp:74</div></div>
<div class="ttc" id="aclassplssvm_1_1csvm_html"><div class="ttname"><a href="classplssvm_1_1csvm.html">plssvm::csvm</a></div><div class="ttdoc">Base class for all C-SVM backends.</div><div class="ttdef"><b>Definition:</b> csvm.hpp:50</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1execution__range_html"><div class="ttname"><a href="classplssvm_1_1detail_1_1execution__range.html">plssvm::detail::execution_range</a></div><div class="ttdoc">Class specifying a backend independent execution range.</div><div class="ttdef"><b>Definition:</b> execution_range.hpp:31</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html">plssvm::detail::gpu_csvm</a></div><div class="ttdoc">A C-SVM implementation for all GPU backends to reduce code duplication.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:46</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a017cfdd2c96bd35fe0eea7645c58ddbe"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a017cfdd2c96bd35fe0eea7645c58ddbe">plssvm::detail::gpu_csvm::generate_q</a></div><div class="ttdeci">std::vector&lt; real_type &gt; generate_q(const parameter&lt; real_type &gt; &amp;params, const std::vector&lt; device_ptr_type&lt; real_type &gt;&gt; &amp;data_d, const std::vector&lt; device_ptr_type&lt; real_type &gt;&gt; &amp;data_last_d, std::size_t num_data_points, const std::vector&lt; std::size_t &gt; &amp;feature_ranges, std::size_t boundary_size) const</div><div class="ttdoc">Calculate the q vector used in the dimensional reduction.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:351</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a233b832ed6fc5991d888a8f96e1d1216"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a233b832ed6fc5991d888a8f96e1d1216">plssvm::detail::gpu_csvm::gpu_csvm</a></div><div class="ttdeci">gpu_csvm(const gpu_csvm &amp;)=delete</div><div class="ttdoc">Delete copy-constructor since a CSVM is a move-only type.</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a3b239311490abe7a71061a33e39b7b27"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a3b239311490abe7a71061a33e39b7b27">plssvm::detail::gpu_csvm::calculate_w</a></div><div class="ttdeci">std::vector&lt; real_type &gt; calculate_w(const std::vector&lt; device_ptr_type&lt; real_type &gt;&gt; &amp;data_d, const std::vector&lt; device_ptr_type&lt; real_type &gt;&gt; &amp;data_last_d, const std::vector&lt; device_ptr_type&lt; real_type &gt;&gt; &amp;alpha_d, std::size_t num_data_points, const std::vector&lt; std::size_t &gt; &amp;feature_ranges) const</div><div class="ttdoc">Precalculate the w vector to speedup up the prediction using the linear kernel function.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:388</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a4365192a069366780b9ca54b5b9f49ec"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a4365192a069366780b9ca54b5b9f49ec">plssvm::detail::gpu_csvm::select_num_used_devices</a></div><div class="ttdeci">std::size_t select_num_used_devices(kernel_function_type kernel, std::size_t num_features) const noexcept</div><div class="ttdoc">Returns the number of usable devices given the kernel function kernel and the number of features num_...</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:284</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a44b7af7e1903ddab1e06348b659a65d3"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a44b7af7e1903ddab1e06348b659a65d3">plssvm::detail::gpu_csvm::solve_system_of_linear_equations</a></div><div class="ttdeci">std::pair&lt; std::vector&lt; float &gt;, float &gt; solve_system_of_linear_equations(const parameter&lt; float &gt; &amp;params, const std::vector&lt; std::vector&lt; float &gt;&gt; &amp;A, std::vector&lt; float &gt; b, float eps, unsigned long long max_iter) const final</div><div class="ttdoc">Solves the equation  using the Conjugated Gradients algorithm.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:101</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a57f8325f3de3c3f8061cfcf25eea8849"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a57f8325f3de3c3f8061cfcf25eea8849">plssvm::detail::gpu_csvm::predict_values</a></div><div class="ttdeci">std::vector&lt; double &gt; predict_values(const parameter&lt; double &gt; &amp;params, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;support_vectors, const std::vector&lt; double &gt; &amp;alpha, double rho, std::vector&lt; double &gt; &amp;w, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;predict_points) const final</div><div class="ttdoc">Uses the already learned model to predict the class of multiple (new) data points.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:119</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a66bc7ee5da121bc9ba323ae5c4c142f7"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a66bc7ee5da121bc9ba323ae5c4c142f7">plssvm::detail::gpu_csvm::setup_data_on_device</a></div><div class="ttdeci">std::tuple&lt; std::vector&lt; device_ptr_type&lt; real_type &gt; &gt;, std::vector&lt; device_ptr_type&lt; real_type &gt; &gt;, std::vector&lt; std::size_t &gt; &gt; setup_data_on_device(const std::vector&lt; std::vector&lt; real_type &gt;&gt; &amp;data, std::size_t num_data_points_to_setup, std::size_t num_features_to_setup, std::size_t boundary_size, std::size_t num_used_devices) const</div><div class="ttdoc">Performs all necessary steps such that the data is available on the device with the correct layout.</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a723115a038e518d4a1ec37bc0fa8b434"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a723115a038e518d4a1ec37bc0fa8b434">plssvm::detail::gpu_csvm::devices_</a></div><div class="ttdeci">std::vector&lt; queue_type &gt; devices_</div><div class="ttdoc">The available/used backend devices.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:280</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a769c736ee34f4511527264b4365ea9b6"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a769c736ee34f4511527264b4365ea9b6">plssvm::detail::gpu_csvm::device_synchronize</a></div><div class="ttdeci">virtual void device_synchronize(const queue_type &amp;queue) const =0</div><div class="ttdoc">Synchronize the device denoted by queue.</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a77085ba427ea262c212c304d77c23dca"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a77085ba427ea262c212c304d77c23dca">plssvm::detail::gpu_csvm::run_device_kernel</a></div><div class="ttdeci">void run_device_kernel(std::size_t device, const parameter&lt; real_type &gt; &amp;params, const device_ptr_type&lt; real_type &gt; &amp;q_d, device_ptr_type&lt; real_type &gt; &amp;r_d, const device_ptr_type&lt; real_type &gt; &amp;x_d, const device_ptr_type&lt; real_type &gt; &amp;data_d, const std::vector&lt; std::size_t &gt; &amp;feature_ranges, real_type QA_cost, real_type add, std::size_t dept, std::size_t boundary_size) const</div><div class="ttdoc">Select the correct kernel based on the value of kernel_ and run it on the device denoted by device.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:433</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a7e47a0051022376215b07ea43799df2d"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a7e47a0051022376215b07ea43799df2d">plssvm::detail::gpu_csvm::run_svm_kernel</a></div><div class="ttdeci">virtual void run_svm_kernel(std::size_t device, const detail::execution_range &amp;range, const parameter&lt; float &gt; &amp;params, const device_ptr_type&lt; float &gt; &amp;q_d, device_ptr_type&lt; float &gt; &amp;r_d, const device_ptr_type&lt; float &gt; &amp;x_d, const device_ptr_type&lt; float &gt; &amp;data_d, float QA_cost, float add, std::size_t num_data_points_padded, std::size_t num_features) const =0</div><div class="ttdoc">Run the main device kernel used in the CG algorithm.</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a854274fb062a44d7c6db3d79ffdc51b4"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a854274fb062a44d7c6db3d79ffdc51b4">plssvm::detail::gpu_csvm::queue_type</a></div><div class="ttdeci">queue_t queue_type</div><div class="ttdoc">The type of the device queue (dependent on the used backend).</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:52</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a85b5b858884716aeb01f707839fadb0f"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a85b5b858884716aeb01f707839fadb0f">plssvm::detail::gpu_csvm::run_w_kernel</a></div><div class="ttdeci">virtual void run_w_kernel(std::size_t device, const detail::execution_range &amp;range, device_ptr_type&lt; double &gt; &amp;w_d, const device_ptr_type&lt; double &gt; &amp;alpha_d, const device_ptr_type&lt; double &gt; &amp;data_d, const device_ptr_type&lt; double &gt; &amp;data_last_d, std::size_t num_data_points, std::size_t num_features) const =0</div><div class="ttdoc">Run the device kernel the calculate the w vector used to speed up the prediction when using the linea...</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a8b1935a343bfab1504dd1e99ff1e12b4"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a8b1935a343bfab1504dd1e99ff1e12b4">plssvm::detail::gpu_csvm::solve_system_of_linear_equations</a></div><div class="ttdeci">std::pair&lt; std::vector&lt; double &gt;, double &gt; solve_system_of_linear_equations(const parameter&lt; double &gt; &amp;params, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;A, std::vector&lt; double &gt; b, double eps, unsigned long long max_iter) const final</div><div class="ttdoc">Solves the equation  using the Conjugated Gradients algorithm.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:105</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a96686349358b90d2961bfa86fb65c307"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a96686349358b90d2961bfa86fb65c307">plssvm::detail::gpu_csvm::gpu_csvm</a></div><div class="ttdeci">gpu_csvm(Args &amp;&amp;...args)</div><div class="ttdoc">Construct a C-SVM forwarding all parameters args to the plssvm::parameter constructor.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:65</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a98339d9aafdf6f12c6fc8e55ecf2728c"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a98339d9aafdf6f12c6fc8e55ecf2728c">plssvm::detail::gpu_csvm::device_reduction</a></div><div class="ttdeci">void device_reduction(std::vector&lt; device_ptr_type&lt; real_type &gt;&gt; &amp;buffer_d, std::vector&lt; real_type &gt; &amp;buffer) const</div><div class="ttdoc">Combines the data in buffer_d from all devices into buffer and distributes them back to each device.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:451</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_a9994493993fd1359c7bf37d54572487f"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#a9994493993fd1359c7bf37d54572487f">plssvm::detail::gpu_csvm::gpu_csvm</a></div><div class="ttdeci">gpu_csvm(plssvm::parameter params={})</div><div class="ttdoc">Construct a C-SVM using the SVM parameter params.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:57</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_aa11267c182956dd778892d92d015bfb1"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#aa11267c182956dd778892d92d015bfb1">plssvm::detail::gpu_csvm::run_predict_kernel</a></div><div class="ttdeci">virtual void run_predict_kernel(const detail::execution_range &amp;range, const parameter&lt; float &gt; &amp;params, device_ptr_type&lt; float &gt; &amp;out_d, const device_ptr_type&lt; float &gt; &amp;alpha_d, const device_ptr_type&lt; float &gt; &amp;point_d, const device_ptr_type&lt; float &gt; &amp;data_d, const device_ptr_type&lt; float &gt; &amp;data_last_d, std::size_t num_support_vectors, std::size_t num_predict_points, std::size_t num_features) const =0</div><div class="ttdoc">Run the device kernel (only on the first device) to predict the new data points point_d.</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_aae80d2f6f0fceaf06b18a2427f87a695"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#aae80d2f6f0fceaf06b18a2427f87a695">plssvm::detail::gpu_csvm::predict_values</a></div><div class="ttdeci">std::vector&lt; float &gt; predict_values(const parameter&lt; float &gt; &amp;params, const std::vector&lt; std::vector&lt; float &gt;&gt; &amp;support_vectors, const std::vector&lt; float &gt; &amp;alpha, float rho, std::vector&lt; float &gt; &amp;w, const std::vector&lt; std::vector&lt; float &gt;&gt; &amp;predict_points) const final</div><div class="ttdoc">Uses the already learned model to predict the class of multiple (new) data points.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:115</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_ab2145facc80b430d141a00918f0ffa38"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#ab2145facc80b430d141a00918f0ffa38">plssvm::detail::gpu_csvm::run_q_kernel</a></div><div class="ttdeci">virtual void run_q_kernel(std::size_t device, const detail::execution_range &amp;range, const parameter&lt; float &gt; &amp;params, device_ptr_type&lt; float &gt; &amp;q_d, const device_ptr_type&lt; float &gt; &amp;data_d, const device_ptr_type&lt; float &gt; &amp;data_last_d, std::size_t num_data_points_padded, std::size_t num_features) const =0</div><div class="ttdoc">Run the device kernel filling the q vector.</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_ab3eaa72ddf8ff84c36878be5a935229b"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#ab3eaa72ddf8ff84c36878be5a935229b">plssvm::detail::gpu_csvm::gpu_csvm</a></div><div class="ttdeci">gpu_csvm(gpu_csvm &amp;&amp;) noexcept=default</div><div class="ttdoc">Default move-constructor since a virtual destructor has been declared. noexcept</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_abd61c52c8399dc50ac0a648e02e2c887"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#abd61c52c8399dc50ac0a648e02e2c887">plssvm::detail::gpu_csvm::run_w_kernel</a></div><div class="ttdeci">virtual void run_w_kernel(std::size_t device, const detail::execution_range &amp;range, device_ptr_type&lt; float &gt; &amp;w_d, const device_ptr_type&lt; float &gt; &amp;alpha_d, const device_ptr_type&lt; float &gt; &amp;data_d, const device_ptr_type&lt; float &gt; &amp;data_last_d, std::size_t num_data_points, std::size_t num_features) const =0</div><div class="ttdoc">Run the device kernel the calculate the w vector used to speed up the prediction when using the linea...</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_abe6edfd2cb23cdd1e54a98ad42116ccd"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#abe6edfd2cb23cdd1e54a98ad42116ccd">plssvm::detail::gpu_csvm::num_available_devices</a></div><div class="ttdeci">std::size_t num_available_devices() const noexcept</div><div class="ttdoc">Return the number of available devices for the current backend.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:93</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_adfb40de23ed08e603e6ffdb9c16a432b"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#adfb40de23ed08e603e6ffdb9c16a432b">plssvm::detail::gpu_csvm::run_q_kernel</a></div><div class="ttdeci">virtual void run_q_kernel(std::size_t device, const detail::execution_range &amp;range, const parameter&lt; double &gt; &amp;params, device_ptr_type&lt; double &gt; &amp;q_d, const device_ptr_type&lt; double &gt; &amp;data_d, const device_ptr_type&lt; double &gt; &amp;data_last_d, std::size_t num_data_points_padded, std::size_t num_features) const =0</div><div class="ttdoc">Run the device kernel filling the q vector.</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_aeccf974410597aa594c09087d8284aa4"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#aeccf974410597aa594c09087d8284aa4">plssvm::detail::gpu_csvm::run_predict_kernel</a></div><div class="ttdeci">virtual void run_predict_kernel(const detail::execution_range &amp;range, const parameter&lt; double &gt; &amp;params, device_ptr_type&lt; double &gt; &amp;out_d, const device_ptr_type&lt; double &gt; &amp;alpha_d, const device_ptr_type&lt; double &gt; &amp;point_d, const device_ptr_type&lt; double &gt; &amp;data_d, const device_ptr_type&lt; double &gt; &amp;data_last_d, std::size_t num_support_vectors, std::size_t num_predict_points, std::size_t num_features) const =0</div><div class="ttdoc">Run the device kernel (only on the first device) to predict the new data points point_d.</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_af771eb7c749984ff0257b48c42236866"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#af771eb7c749984ff0257b48c42236866">plssvm::detail::gpu_csvm::solve_system_of_linear_equations_impl</a></div><div class="ttdeci">std::pair&lt; std::vector&lt; real_type &gt;, real_type &gt; solve_system_of_linear_equations_impl(const parameter&lt; real_type &gt; &amp;params, const std::vector&lt; std::vector&lt; real_type &gt;&gt; &amp;A, std::vector&lt; real_type &gt; b, real_type eps, unsigned long long max_iter) const</div><div class="ttdoc">Solves the equation  using the Conjugated Gradients algorithm.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:479</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_af961e05755daaa546dca0c2b31943484"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#af961e05755daaa546dca0c2b31943484">plssvm::detail::gpu_csvm::device_ptr_type</a></div><div class="ttdeci">device_ptr_t&lt; real_type &gt; device_ptr_type</div><div class="ttdoc">The type of the device pointer (dependent on the used backend).</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:50</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_afb6d0b23bf3292f2652442ca83004342"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#afb6d0b23bf3292f2652442ca83004342">plssvm::detail::gpu_csvm::run_svm_kernel</a></div><div class="ttdeci">virtual void run_svm_kernel(std::size_t device, const detail::execution_range &amp;range, const parameter&lt; double &gt; &amp;params, const device_ptr_type&lt; double &gt; &amp;q_d, device_ptr_type&lt; double &gt; &amp;r_d, const device_ptr_type&lt; double &gt; &amp;x_d, const device_ptr_type&lt; double &gt; &amp;data_d, double QA_cost, double add, std::size_t num_data_points_padded, std::size_t num_features) const =0</div><div class="ttdoc">Run the main device kernel used in the CG algorithm.</div></div>
<div class="ttc" id="aclassplssvm_1_1detail_1_1gpu__csvm_html_aff263192e34c8bf6342bb542bd4c05e0"><div class="ttname"><a href="classplssvm_1_1detail_1_1gpu__csvm.html#aff263192e34c8bf6342bb542bd4c05e0">plssvm::detail::gpu_csvm::predict_values_impl</a></div><div class="ttdeci">std::vector&lt; real_type &gt; predict_values_impl(const parameter&lt; real_type &gt; &amp;params, const std::vector&lt; std::vector&lt; real_type &gt;&gt; &amp;support_vectors, const std::vector&lt; real_type &gt; &amp;alpha, real_type rho, std::vector&lt; real_type &gt; &amp;w, const std::vector&lt; std::vector&lt; real_type &gt;&gt; &amp;predict_points) const</div><div class="ttdoc">Uses the already learned model to predict the class of multiple (new) data points.</div><div class="ttdef"><b>Definition:</b> gpu_csvm.hpp:658</div></div>
<div class="ttc" id="aconstants_8hpp_html"><div class="ttname"><a href="constants_8hpp.html">constants.hpp</a></div><div class="ttdoc">Global type definitions and compile-time constants.</div></div>
<div class="ttc" id="acsvm_8hpp_html"><div class="ttname"><a href="csvm_8hpp.html">csvm.hpp</a></div><div class="ttdoc">Defines the base class for all C-SVM backends and implements the functionality shared by all of them.</div></div>
<div class="ttc" id="aexecution__range_8hpp_html"><div class="ttname"><a href="execution__range_8hpp.html">execution_range.hpp</a></div><div class="ttdoc">Implement a backend independent class used to specify the execution range for all kernel invocations.</div></div>
<div class="ttc" id="alayout_8hpp_html"><div class="ttname"><a href="layout_8hpp.html">layout.hpp</a></div><div class="ttdoc">Defines functions to convert 2D vectors to 1D SoA or AoS vectors.</div></div>
<div class="ttc" id="alogger_8hpp_html"><div class="ttname"><a href="logger_8hpp.html">logger.hpp</a></div><div class="ttdoc">Defines a simple logging function.</div></div>
<div class="ttc" id="anamespaceplssvm_1_1cuda_1_1detail_html_a993ed255276400b7b0b1d05a66c4d78d"><div class="ttname"><a href="namespaceplssvm_1_1cuda_1_1detail.html#a993ed255276400b7b0b1d05a66c4d78d">plssvm::cuda::detail::device_synchronize</a></div><div class="ttdeci">void device_synchronize(int device)</div><div class="ttdoc">Wait for the compute device to finish.</div></div>
<div class="ttc" id="anamespaceplssvm_1_1detail_html"><div class="ttname"><a href="namespaceplssvm_1_1detail.html">plssvm::detail</a></div><div class="ttdoc">Namespace containing implementation details. Should not directly be used by users.</div><div class="ttdef"><b>Definition:</b> csvm.hpp:27</div></div>
<div class="ttc" id="anamespaceplssvm_1_1detail_html_a1924673c0771230d7f653b2346578acc"><div class="ttname"><a href="namespaceplssvm_1_1detail.html#a1924673c0771230d7f653b2346578acc">plssvm::detail::log</a></div><div class="ttdeci">void log(const verbosity_level verb, const std::string_view msg, Args &amp;&amp;...args)</div><div class="ttdef"><b>Definition:</b> logger.hpp:109</div></div>
<div class="ttc" id="anamespaceplssvm_1_1detail_html_ae3035abd433eac136aaa8381d80adc7f"><div class="ttname"><a href="namespaceplssvm_1_1detail.html#ae3035abd433eac136aaa8381d80adc7f">plssvm::detail::transform_to_layout</a></div><div class="ttdeci">std::vector&lt; real_type &gt; transform_to_layout(const layout_type layout, const std::vector&lt; std::vector&lt; real_type &gt;&gt; &amp;matrix, const std::size_t boundary_size, const std::size_t num_points)</div><div class="ttdoc">Convert a 2D matrix into a 1D array in the layout adding boundary_size values per data point or featu...</div><div class="ttdef"><b>Definition:</b> layout.hpp:118</div></div>
<div class="ttc" id="anamespaceplssvm_1_1detail_html_ae892fe94f0993706ca5a964c6113e274aa39d8591483b67fb637bb445f9f4f059"><div class="ttname"><a href="namespaceplssvm_1_1detail.html#ae892fe94f0993706ca5a964c6113e274aa39d8591483b67fb637bb445f9f4f059">plssvm::detail::layout_type::soa</a></div><div class="ttdeci">@ soa</div></div>
<div class="ttc" id="anamespaceplssvm_1_1operators_html"><div class="ttname"><a href="namespaceplssvm_1_1operators.html">plssvm::operators</a></div><div class="ttdoc">Namespace containing operator overloads for std::vector and other mathematical functions on vectors.</div><div class="ttdef"><b>Definition:</b> core.hpp:49</div></div>
<div class="ttc" id="anamespaceplssvm_1_1operators_html_a6344cb6d38f1fe59cfd7ba0f8b3382a3"><div class="ttname"><a href="namespaceplssvm_1_1operators.html#a6344cb6d38f1fe59cfd7ba0f8b3382a3">plssvm::operators::sum</a></div><div class="ttdeci">T sum(const std::vector&lt; T &gt; &amp;vec)</div><div class="ttdoc">Accumulate all elements in the std::vector vec.</div><div class="ttdef"><b>Definition:</b> operators.hpp:144</div></div>
<div class="ttc" id="anamespaceplssvm_html"><div class="ttname"><a href="namespaceplssvm.html">plssvm</a></div><div class="ttdoc">The main namespace containing all public API functions.</div><div class="ttdef"><b>Definition:</b> backend_types.hpp:24</div></div>
<div class="ttc" id="anamespaceplssvm_html_a30a9e7fd7e5c3e501fb0653f392f5741a4ad8aa3a3571ea912a6ec5ea5fdcc93c"><div class="ttname"><a href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741a4ad8aa3a3571ea912a6ec5ea5fdcc93c">plssvm::verbosity_level::timing</a></div><div class="ttdeci">@ timing</div></div>
<div class="ttc" id="anamespaceplssvm_html_a30a9e7fd7e5c3e501fb0653f392f5741aa3cf19501138f29d2107a275e7670846"><div class="ttname"><a href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741aa3cf19501138f29d2107a275e7670846">plssvm::verbosity_level::libsvm</a></div><div class="ttdeci">@ libsvm</div></div>
<div class="ttc" id="anamespaceplssvm_html_a30a9e7fd7e5c3e501fb0653f392f5741ae9dc924f238fa6cc29465942875fe8f0"><div class="ttname"><a href="namespaceplssvm.html#a30a9e7fd7e5c3e501fb0653f392f5741ae9dc924f238fa6cc29465942875fe8f0">plssvm::verbosity_level::full</a></div><div class="ttdeci">@ full</div></div>
<div class="ttc" id="anamespaceplssvm_html_a76052beb2b262c165f1811c5064ca1b5"><div class="ttname"><a href="namespaceplssvm.html#a76052beb2b262c165f1811c5064ca1b5">plssvm::THREAD_BLOCK_SIZE</a></div><div class="ttdeci">constexpr kernel_index_type THREAD_BLOCK_SIZE</div><div class="ttdoc">Global compile-time constant used for internal caching. May be changed during the CMake configuration...</div><div class="ttdef"><b>Definition:</b> constants.hpp:25</div></div>
<div class="ttc" id="anamespaceplssvm_html_aa6180d48d5afcdf753fd639d138f180c"><div class="ttname"><a href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180c">plssvm::kernel_function_type</a></div><div class="ttdeci">kernel_function_type</div><div class="ttdoc">Enum class for all implemented kernel functions.</div><div class="ttdef"><b>Definition:</b> kernel_function_types.hpp:31</div></div>
<div class="ttc" id="anamespaceplssvm_html_aa6180d48d5afcdf753fd639d138f180ca1c2fc056f2b0d4685d95adb8764a3912"><div class="ttname"><a href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180ca1c2fc056f2b0d4685d95adb8764a3912">plssvm::kernel_function_type::rbf</a></div><div class="ttdeci">@ rbf</div></div>
<div class="ttc" id="anamespaceplssvm_html_aa6180d48d5afcdf753fd639d138f180ca89693d3333328e76f4fdeed379e8f9ea"><div class="ttname"><a href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180ca89693d3333328e76f4fdeed379e8f9ea">plssvm::kernel_function_type::polynomial</a></div><div class="ttdeci">@ polynomial</div></div>
<div class="ttc" id="anamespaceplssvm_html_aa6180d48d5afcdf753fd639d138f180ca9a932b3cb396238423eb2f33ec17d6aa"><div class="ttname"><a href="namespaceplssvm.html#aa6180d48d5afcdf753fd639d138f180ca9a932b3cb396238423eb2f33ec17d6aa">plssvm::kernel_function_type::linear</a></div><div class="ttdeci">@ linear</div></div>
<div class="ttc" id="anamespaceplssvm_html_ac7c75fadcf6b7f3ea0d1bb831a70933d"><div class="ttname"><a href="namespaceplssvm.html#ac7c75fadcf6b7f3ea0d1bb831a70933d">plssvm::INTERNAL_BLOCK_SIZE</a></div><div class="ttdeci">constexpr kernel_index_type INTERNAL_BLOCK_SIZE</div><div class="ttdoc">Global compile-time constant used for internal caching. May be changed during the CMake configuration...</div><div class="ttdef"><b>Definition:</b> constants.hpp:32</div></div>
<div class="ttc" id="anamespaceplssvm_html_ae76872fe47a5337ea0c783648835554d"><div class="ttname"><a href="namespaceplssvm.html#ae76872fe47a5337ea0c783648835554d">plssvm::kernel_function</a></div><div class="ttdeci">real_type kernel_function(const std::vector&lt; real_type &gt; &amp;xi, const std::vector&lt; real_type &gt; &amp;xj, Args &amp;&amp;...args)</div><div class="ttdoc">Computes the value of the two vectors xi and xj using the kernel function determined at compile-time.</div><div class="ttdef"><b>Definition:</b> kernel_function_types.hpp:76</div></div>
<div class="ttc" id="aparameter_8hpp_html"><div class="ttname"><a href="parameter_8hpp.html">parameter.hpp</a></div><div class="ttdoc">Implements the parameter class encapsulating all important C-SVM parameters.</div></div>
<div class="ttc" id="aperformance__tracker_8hpp_html"><div class="ttname"><a href="performance__tracker_8hpp.html">performance_tracker.hpp</a></div><div class="ttdoc">Defines a performance tracker which can dump performance information in a YAML file.</div></div>
<div class="ttc" id="aperformance__tracker_8hpp_html_aa68da95e449ddf405004e93907a0f7a0"><div class="ttname"><a href="performance__tracker_8hpp.html#aa68da95e449ddf405004e93907a0f7a0">PLSSVM_DETAIL_PERFORMANCE_TRACKER_ADD_TRACKING_ENTRY</a></div><div class="ttdeci">#define PLSSVM_DETAIL_PERFORMANCE_TRACKER_ADD_TRACKING_ENTRY(entry)</div><div class="ttdoc">Defines the PLSSVM_DETAIL_PERFORMANCE_TRACKER_ADD_TRACKING_ENTRY macro if PLSSVM_PERFORMANCE_TRACKER_...</div><div class="ttdef"><b>Definition:</b> performance_tracker.hpp:245</div></div>
<div class="ttc" id="astructplssvm_1_1detail_1_1parameter_html"><div class="ttname"><a href="structplssvm_1_1detail_1_1parameter.html">plssvm::detail::parameter&lt; double &gt;</a></div></div>
<div class="ttc" id="astructplssvm_1_1detail_1_1parameter_html_a338e4c74cdc29d696b611a97f4406ea7"><div class="ttname"><a href="structplssvm_1_1detail_1_1parameter.html#a338e4c74cdc29d696b611a97f4406ea7">plssvm::detail::parameter::cost</a></div><div class="ttdeci">default_value&lt; real_type &gt; cost</div><div class="ttdoc">The cost parameter in the C-SVM.</div><div class="ttdef"><b>Definition:</b> parameter.hpp:165</div></div>
<div class="ttc" id="astructplssvm_1_1detail_1_1parameter_html_af4ab7baef882761ac61a7f353ed8a655"><div class="ttname"><a href="structplssvm_1_1detail_1_1parameter.html#af4ab7baef882761ac61a7f353ed8a655">plssvm::detail::parameter::kernel_type</a></div><div class="ttdeci">default_value&lt; kernel_function_type &gt; kernel_type</div><div class="ttdoc">The used kernel function: linear, polynomial, or radial basis functions (rbf).</div><div class="ttdef"><b>Definition:</b> parameter.hpp:157</div></div>
<div class="ttc" id="astructplssvm_1_1detail_1_1tracking__entry_html"><div class="ttname"><a href="structplssvm_1_1detail_1_1tracking__entry.html">plssvm::detail::tracking_entry</a></div><div class="ttdoc">A single tracking entry containing a specific category, a unique name, and the actual value to be tra...</div><div class="ttdef"><b>Definition:</b> performance_tracker.hpp:40</div></div>
<div class="ttc" id="astructplssvm_1_1operators_1_1transposed_html"><div class="ttname"><a href="structplssvm_1_1operators_1_1transposed.html">plssvm::operators::transposed</a></div><div class="ttdoc">Wrapper struct for overloading the dot product operator.</div><div class="ttdef"><b>Definition:</b> operators.hpp:99</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu May 11 2023 14:12:15 for PLSSVM - Parallel Least Squares Support Vector Machine by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
